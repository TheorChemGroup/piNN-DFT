{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0262a903-f1e3-4fed-bb5c-0c8d2086c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/python/envs/pytorch1_11/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import h5py    \n",
    "import numpy as np    \n",
    "import torch\n",
    "import csv\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "from NN_models import NN_2_256, NN_8_256, NN_8_64\n",
    "\n",
    "\n",
    "def ref(x, y):\n",
    "    ''' \n",
    "    returns reference energies for points of a reaction grid from Reference_data.csv\n",
    "    '''\n",
    "    hartree2kcal = 627.5095\n",
    "    with open(\"Reference_data.csv\", newline='', encoding='cp1251') as csvfile:\n",
    "        ref_file = csv.reader(csvfile, delimiter=\",\")\n",
    "        k = 1\n",
    "        if y == 391:\n",
    "            k = hartree2kcal\n",
    "        ref = []\n",
    "        for n, i in enumerate(ref_file):\n",
    "            if x <= n + 1 <= y:\n",
    "                ref.append((i[0], float(i[2]) * k))\n",
    "\n",
    "        return ref\n",
    "\n",
    "def load_ref_energies():\n",
    "    '''Returns {db_name: [equation, energy]}'''\n",
    "    ref_e = { # Получение референсных энергий\n",
    "        \"MGAE109\":ref(8, 116),\n",
    "        \"IP13\":ref(155, 167),\n",
    "        \"EA13\":ref(180, 192),\n",
    "        \"PA8\":ref(195, 202),\n",
    "        \"DBH76\":ref(251, 288) + ref(291, 328),\n",
    "        \"NCCE31\":ref(331, 361),\n",
    "        \"ABDE4\":ref(206, 209),\n",
    "        # \"AE17\":ref(375, 391),\n",
    "        \"pTC13\":ref(232, 234) + ref(237, 241) + ref(244, 248)\n",
    "        } \n",
    "    return ref_e\n",
    "\n",
    "def load_component_names():\n",
    "    '''\n",
    "    Returns {db_name: {id: {'Components': [...], 'Coefficients: [...]'\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "     which is a dictionary with Components and Coefficients data about all reactions\n",
    "    '''\n",
    "    with open(\"total_dataframe_sorted_final.csv\", newline='', encoding='cp1251') as csvfile:\n",
    "        ref_file = csv.reader(csvfile, delimiter=\",\")\n",
    "        ref = dict()\n",
    "        current_database = None\n",
    "        \n",
    "        for n, line in enumerate(ref_file):\n",
    "            line = np.array(line)\n",
    "            if n == 0:\n",
    "                components = np.array(line)\n",
    "            else:\n",
    "                reaction_id = int(line[0])\n",
    "                reaction_database = line[1]\n",
    "                reaction_component_num = np.nonzero(list(map(float, line[2:])))[0] + 2\n",
    "                if reaction_database in ref:\n",
    "                    ref[reaction_database][reaction_id] = {'Components': components[reaction_component_num], 'Coefficients': line[reaction_component_num]}\n",
    "                else: \n",
    "                    ref[reaction_database] = {reaction_id: {'Components': components[reaction_component_num], 'Coefficients': line[reaction_component_num]}}\n",
    "        return ref\n",
    "    \n",
    "    \n",
    "def get_compounds_coefs_energy_v2(reactions, energies):\n",
    "    '''Returns {id: \n",
    "                    {'Components': [...], 'Coefficients: [...]', 'Energy: float', Database: str\n",
    "                                }\n",
    "                            }\n",
    "    which is a dictionaty from load_component_names with Energy information added\n",
    "    '''\n",
    "    data_final = dict()\n",
    "    i = 0\n",
    "    databases = load_ref_energies().keys()\n",
    "    for database in databases:\n",
    "        data = reactions[database]\n",
    "        for reaction in data:\n",
    "            data_final[i] = {'Database': database,\n",
    "                             'Components': reactions[database][reaction]['Components'], #.astype(object),\n",
    "                             'Coefficients': torch.Tensor(reactions[database][reaction]['Coefficients'].astype(np.float32)),\n",
    "                             'Energy': torch.Tensor(np.array(energies[database][reaction][1]))\n",
    "            \n",
    "        }\n",
    "            i += 1\n",
    "        \n",
    "    return data_final\n",
    "\n",
    "\n",
    "def get_h5_names(reaction):\n",
    "    '''reaction must be from the function get_compounds_coefs_energy_v2'''\n",
    "    database_match = {\n",
    "        'MGAE109': 'mgae109',\n",
    "        'IP13': 'ip13',\n",
    "        'EA13': 'ea13',\n",
    "        'PA8': 'pa8',\n",
    "        'DBH76': 'ntbh38',\n",
    "        'NCCE31': 'ncce31',\n",
    "        'ABDE4': 'abde4',\n",
    "        'AE17': 'ae17',\n",
    "        'pTC13': 'ptc13'\n",
    "    }\n",
    "    names = []\n",
    "    for elem in reaction['Components']:\n",
    "        database = database_match[reaction['Database']]\n",
    "        names.append(f'{elem}.h5')\n",
    "    return names\n",
    "\n",
    "\n",
    "def add_reaction_info_from_h5(reaction):\n",
    "    '''\n",
    "    reaction must be from get_compounds_coefs_energy_v2\n",
    "    returns merged descriptos array X, integration weights, \n",
    "    a and b densities and indexes for backsplitting\n",
    "    \n",
    "    Adds the following information to the reaction dict using h5 files from the dataset:\n",
    "    Grid : np.array with grid descriptors\n",
    "    Weights : list with integration weights of grid points\n",
    "    Densities : np.array with alpha and beta densities data for grid points\n",
    "    HF_energies : list of Total HF energy (T+V) which needs to be added to E_xc\n",
    "    backsplit_ind: list of indexes where we concatenate molecules' grids\n",
    "    '''\n",
    "    X = np.array([])\n",
    "    backsplit_ind = []\n",
    "    HF_energies = np.array([])\n",
    "    for component_filename in get_h5_names(reaction):\n",
    "        with h5py.File(f'data/{component_filename}', \"r\") as f:\n",
    "            HF_energies = np.append(HF_energies, f[\"ener\"][:][0])\n",
    "            X_raw = np.array(f[\"grid\"][:])\n",
    "            if len(X) == 0:\n",
    "                X = X_raw[:, 3:-1]\n",
    "            else:\n",
    "                X = np.vstack((X, X_raw[:, 3:-1]))\n",
    "            backsplit_ind.append(len(X))\n",
    "    densities = X[:, 1:3]\n",
    "    weights = X[:,0]\n",
    "    X = X[:, 1:]\n",
    "\n",
    "    labels = ['Grid', 'Weights', 'Densities', 'HF_energies', 'backsplit_ind']\n",
    "    values = [X, weights, densities, HF_energies, backsplit_ind]\n",
    "    for label, value in zip(labels, values):\n",
    "        reaction[label] = torch.Tensor(value)\n",
    "\n",
    "    return reaction\n",
    "\n",
    "\n",
    "def make_reactions_dict():\n",
    "    '''\n",
    "    Returns a dict like {reaction_id: {*reaction info}} with all info available listed below:\n",
    "    ['Database', 'Components', 'Coefficients', 'Energy', 'Grid', 'Weights', 'Densities', 'HF_energies', 'backsplit_ind']\n",
    "    '''\n",
    "    data = get_compounds_coefs_energy_v2(load_component_names(), load_ref_energies())\n",
    "    for i in data.keys():\n",
    "        data[i] = add_reaction_info_from_h5(data[i])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "data = make_reactions_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cbf693f-e977-4bbd-983d-543a94ec2ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'MGAE109',\n",
       " 'Components': array(['C_mgae109', 'H_mgae109', 'CH_mgae109'], dtype='<U20'),\n",
       " 'Coefficients': tensor([ 1.,  1., -1.]),\n",
       " 'Energy': tensor(84.2300),\n",
       " 'Grid': tensor([[6.3204e+01, 6.3213e+01, 1.9346e+00,  ..., 1.9352e+00, 7.5028e+00,\n",
       "          3.8268e-03],\n",
       "         [6.3204e+01, 6.3213e+01, 1.6335e+02,  ..., 1.6340e+02, 7.8221e+00,\n",
       "          3.2312e-01],\n",
       "         [6.3201e+01, 6.3210e+01, 2.1850e+03,  ..., 2.1857e+03, 1.1821e+01,\n",
       "          4.3224e+00],\n",
       "         ...,\n",
       "         [4.8742e-04, 3.2433e-04, 9.2476e-07,  ..., 5.0238e-07, 2.6551e-04,\n",
       "          1.9790e-04],\n",
       "         [6.3506e-04, 4.3839e-04, 1.5955e-06,  ..., 9.3007e-07, 3.5282e-04,\n",
       "          2.7110e-04],\n",
       "         [4.8742e-04, 3.2433e-04, 9.2476e-07,  ..., 5.0238e-07, 2.6551e-04,\n",
       "          1.9790e-04]]),\n",
       " 'Weights': tensor([2.5717e-17, 9.9780e-15, 3.2611e-13,  ..., 2.6018e-02, 2.2653e-02,\n",
       "         2.6018e-02]),\n",
       " 'Densities': tensor([[6.3204e+01, 6.3213e+01],\n",
       "         [6.3204e+01, 6.3213e+01],\n",
       "         [6.3201e+01, 6.3210e+01],\n",
       "         ...,\n",
       "         [4.8742e-04, 3.2433e-04],\n",
       "         [6.3506e-04, 4.3839e-04],\n",
       "         [4.8742e-04, 3.2433e-04]]),\n",
       " 'HF_energies': tensor([-32.6318,  -0.1908, -32.8681]),\n",
       " 'backsplit_ind': tensor([ 31098.,  64932., 129864.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dbf037-f335-40fc-8ce5-cca32100e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_components(data):\n",
    "    for i in data:\n",
    "        data[i]['Components'] = data[i]['Components'].tobytes()\n",
    "        \n",
    "encode_components(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a25894b-9004-4d97-a139-16ae4137ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_single = [0.0310907, 0.01554535, \n",
    "            3.72744,   7.06042,\n",
    "            12.9352,   18.0578,\n",
    "            -0.10498,  -0.32500,\n",
    "            0.0310907,  0.01554535,  -1/(6*np.pi**2),\n",
    "            13.0720,    20.1231,      1.06835,\n",
    "            42.7198,   101.578,      11.4813,\n",
    "            -0.409286,  -0.743294,   -0.228344,\n",
    "            1]\n",
    "\n",
    "nconstants = len(y_single)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "device\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        self.data[i].pop('Database', None)\n",
    "#         <U20\n",
    "\n",
    "        return self.data[i], y_single\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.keys())\n",
    "\n",
    "\n",
    "train_set = Dataset(data=data)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set,\n",
    "                                               batch_size=1,\n",
    "                                               num_workers=1,\n",
    "                                               shuffle=True)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3424dc36-9e76-41ea-bea5-ae98fe9dfbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.frombuffer(X_batch['Components'][0], dtype='<U20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3ec4ebf-9e04-4a1d-89aa-96b6862278f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, train_dataloader, n_epochs=2):\n",
    "    \n",
    "    torch.set_printoptions(precision=5)\n",
    "    \n",
    "    train_loss_mse = []\n",
    "    train_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Epoch', epoch+1)\n",
    "        # train\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        train_mse_losses_per_epoch = []\n",
    "        train_mae_losses_per_epoch = []\n",
    "        \n",
    "        progress_bar = tqdm(train_dataloader)\n",
    "        for X_batch, y_batch in progress_bar:\n",
    "            X_batch = X_batch['Grid'][0]\n",
    "            y_batch = torch.tile(torch.Tensor(y_batch), [X_batch.shape[0],1])\n",
    "            # print(X_batch)\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # print(predictions, y_batch)\n",
    "            train_mse_losses_per_epoch.append(loss.item())\n",
    "            train_mae_losses_per_epoch.append(mean_absolute_error(predictions.cpu().detach(), y_batch.cpu().detach()))\n",
    "            scheduler.step()\n",
    "            # print(f\"MAE: {(predictions - y_batch).mean()}, MSE: {((predictions - y_batch)**2).mean()}\")\n",
    "            progress_bar.set_postfix(MAE = (predictions - y_batch).mean().item(), MSE = ((predictions - y_batch)**2).mean().item())\n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))\n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "        \n",
    "        print(f'train RMSE Loss = {train_loss_mse[epoch] ** 0.5:.8f}')\n",
    "        print(f'train MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    " \n",
    "    return train_loss_mse, train_loss_mae, predictions[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a4a42f6-a9ba-49da-8b6e-7098c1e254c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_2_256(DFT='SVWN')\n",
    "# model.load_state_dict(torch.load('predoptimized_3.param'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-2, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 300, 500], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59eff639-e8f9-44b8-bfa8-57a763eb049d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [22:23<00:00,  5.03s/it, MAE=-.785, MSE=13.9]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE Loss = 11.83396229\n",
      "train MAE Loss = 2.60232377\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [22:07<00:00,  4.97s/it, MAE=-1.44, MSE=15.4]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE Loss = 4.63451379\n",
      "train MAE Loss = 1.58513415\n",
      "predicted coef \n",
      " [ 3.92311215e-02  1.33161545e-02  2.38649774e+00  4.51494789e+00\n",
      "  1.35723972e+01  1.91060543e+01 -5.10632694e-02 -2.81686008e-01\n",
      " -1.51830763e-02 -4.12280858e-03  1.69434845e-02  9.44185162e+00\n",
      "  1.54124393e+01  1.19533360e+00  4.48689117e+01  1.04770142e+02\n",
      "  1.17419872e+01 -4.07811344e-01 -7.47409284e-01 -2.29383066e-01\n",
      "  1.04700291e+00]\n",
      "exact coef \n",
      " [ 3.10907000e-02  1.55453500e-02  3.72744000e+00  7.06042000e+00\n",
      "  1.29352000e+01  1.80578000e+01 -1.04980000e-01 -3.25000000e-01\n",
      "  3.10907000e-02  1.55453500e-02 -1.68868639e-02  1.30720000e+01\n",
      "  2.01231000e+01  1.06835000e+00  4.27198000e+01  1.01578000e+02\n",
      "  1.14813000e+01 -4.09286000e-01 -7.43294000e-01 -2.28344000e-01\n",
      "  1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss_mse, train_loss_mae, preds = train(model, criterion, optimizer, \n",
    "                                              scheduler, train_dataloader, n_epochs=3)\n",
    "\n",
    "# print(train_loss_mse, train_loss_mae, test_loss_mse, test_loss_mae)\n",
    "print('predicted coef', '\\n', preds)\n",
    "print('exact coef', '\\n', np.array(y_single))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347201f9-8af2-4794-8a56-e831b93ad860",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'predoptimized_2_256.param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d10b7-e877-4f06-ab5f-ca7270cd29da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000eccb-ba5b-4f74-b71f-bab526adb440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.11 [python-pytorch1_11]",
   "language": "python",
   "name": "conda-env-python-pytorch1_11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
