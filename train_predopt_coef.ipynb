{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0262a903-f1e3-4fed-bb5c-0c8d2086c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py    \n",
    "import numpy as np    \n",
    "import torch\n",
    "import gc\n",
    "import csv\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "from NN_models import NN_2_256, NN_8_256, NN_8_64\n",
    "\n",
    "\n",
    "def ref(x, y):\n",
    "    ''' \n",
    "    returns reference energies for points of a reaction grid from Reference_data.csv\n",
    "    '''\n",
    "    hartree2kcal = 627.5095\n",
    "    with open(\"Reference_data.csv\", newline='', encoding='cp1251') as csvfile:\n",
    "        ref_file = csv.reader(csvfile, delimiter=\",\")\n",
    "        k = 1\n",
    "        if y == 391:\n",
    "            k = hartree2kcal\n",
    "        ref = []\n",
    "        for n, i in enumerate(ref_file):\n",
    "            if x <= n + 1 <= y:\n",
    "                ref.append((i[0], float(i[2]) * k))\n",
    "\n",
    "        return ref\n",
    "\n",
    "def load_ref_energies():\n",
    "    '''Returns {db_name: [equation, energy]}'''\n",
    "    ref_e = { # Получение референсных энергий\n",
    "        \"MGAE109\":ref(8, 116),\n",
    "        \"IP13\":ref(155, 167),\n",
    "        \"EA13\":ref(180, 192),\n",
    "        \"PA8\":ref(195, 202),\n",
    "        \"DBH76\":ref(251, 288) + ref(291, 328),\n",
    "        \"NCCE31\":ref(331, 361),\n",
    "        \"ABDE4\":ref(206, 209),\n",
    "        # \"AE17\":ref(375, 391),\n",
    "        \"pTC13\":ref(232, 234) + ref(237, 241) + ref(244, 248)\n",
    "        } \n",
    "    return ref_e\n",
    "\n",
    "def load_component_names():\n",
    "    '''\n",
    "    Returns {db_name: {id: {'Components': [...], 'Coefficients: [...]'\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "     which is a dictionary with Components and Coefficients data about all reactions\n",
    "    '''\n",
    "    with open(\"total_dataframe_sorted_final.csv\", newline='', encoding='cp1251') as csvfile:\n",
    "        ref_file = csv.reader(csvfile, delimiter=\",\")\n",
    "        ref = dict()\n",
    "        current_database = None\n",
    "        \n",
    "        for n, line in enumerate(ref_file):\n",
    "            line = np.array(line)\n",
    "            if n == 0:\n",
    "                components = np.array(line)\n",
    "            else:\n",
    "                reaction_id = int(line[0])\n",
    "                reaction_database = line[1]\n",
    "                reaction_component_num = np.nonzero(list(map(float, line[2:])))[0] + 2\n",
    "                if reaction_database in ref:\n",
    "                    ref[reaction_database][reaction_id] = {'Components': components[reaction_component_num], 'Coefficients': line[reaction_component_num]}\n",
    "                else: \n",
    "                    ref[reaction_database] = {reaction_id: {'Components': components[reaction_component_num], 'Coefficients': line[reaction_component_num]}}\n",
    "        return ref\n",
    "    \n",
    "    \n",
    "def get_compounds_coefs_energy_v2(reactions, energies):\n",
    "    '''Returns {id: \n",
    "                    {'Components': [...], 'Coefficients: [...]', 'Energy: float', Database: str\n",
    "                                }\n",
    "                            }\n",
    "    which is a dictionaty from load_component_names with Energy information added\n",
    "    '''\n",
    "    data_final = dict()\n",
    "    i = 0\n",
    "    databases = load_ref_energies().keys()\n",
    "    for database in databases:\n",
    "        data = reactions[database]\n",
    "        for reaction in data:\n",
    "            data_final[i] = {'Database': database,\n",
    "                             'Components': reactions[database][reaction]['Components'], #.astype(object),\n",
    "                             'Coefficients': torch.Tensor(reactions[database][reaction]['Coefficients'].astype(np.float32)),\n",
    "                             'Energy': torch.Tensor(np.array(energies[database][reaction][1]))\n",
    "            \n",
    "        }\n",
    "            i += 1\n",
    "        \n",
    "    return data_final\n",
    "\n",
    "\n",
    "def get_h5_names(reaction):\n",
    "    '''reaction must be from the function get_compounds_coefs_energy_v2'''\n",
    "    database_match = {\n",
    "        'MGAE109': 'mgae109',\n",
    "        'IP13': 'ip13',\n",
    "        'EA13': 'ea13',\n",
    "        'PA8': 'pa8',\n",
    "        'DBH76': 'ntbh38',\n",
    "        'NCCE31': 'ncce31',\n",
    "        'ABDE4': 'abde4',\n",
    "        'AE17': 'ae17',\n",
    "        'pTC13': 'ptc13'\n",
    "    }\n",
    "    names = []\n",
    "    for elem in reaction['Components']:\n",
    "        database = database_match[reaction['Database']]\n",
    "        names.append(f'{elem}.h5')\n",
    "    return names\n",
    "\n",
    "\n",
    "def add_reaction_info_from_h5(reaction):\n",
    "    '''\n",
    "    reaction must be from get_compounds_coefs_energy_v2\n",
    "    returns merged descriptos array X, integration weights, \n",
    "    a and b densities and indexes for backsplitting\n",
    "    \n",
    "    Adds the following information to the reaction dict using h5 files from the dataset:\n",
    "    Grid : np.array with grid descriptors\n",
    "    Weights : list with integration weights of grid points\n",
    "    Densities : np.array with alpha and beta densities data for grid points\n",
    "    HF_energies : list of Total HF energy (T+V) which needs to be added to E_xc\n",
    "    backsplit_ind: list of indexes where we concatenate molecules' grids\n",
    "    '''\n",
    "    X = np.array([])\n",
    "    backsplit_ind = []\n",
    "    HF_energies = np.array([])\n",
    "    for component_filename in get_h5_names(reaction):\n",
    "        with h5py.File(f'data/{component_filename}', \"r\") as f:\n",
    "            HF_energies = np.append(HF_energies, f[\"ener\"][:][0])\n",
    "            X_raw = np.array(f[\"grid\"][:])\n",
    "            if len(X) == 0:\n",
    "                X = X_raw[:, 3:-1]\n",
    "            else:\n",
    "                X = np.vstack((X, X_raw[:, 3:-1]))\n",
    "            backsplit_ind.append(len(X))\n",
    "    densities = X[:, 1:3]\n",
    "    weights = X[:,0]\n",
    "    X = X[:, 1:]\n",
    "\n",
    "    labels = ['Grid', 'Weights', 'Densities', 'HF_energies', 'backsplit_ind']\n",
    "    values = [X, weights, densities, HF_energies, backsplit_ind]\n",
    "    for label, value in zip(labels, values):\n",
    "        reaction[label] = torch.Tensor(value)\n",
    "\n",
    "    return reaction\n",
    "\n",
    "\n",
    "def make_reactions_dict():\n",
    "    '''\n",
    "    Returns a dict like {reaction_id: {*reaction info}} with all info available listed below:\n",
    "    ['Database', 'Components', 'Coefficients', 'Energy', 'Grid', 'Weights', 'Densities', 'HF_energies', 'backsplit_ind']\n",
    "    '''\n",
    "    data = get_compounds_coefs_energy_v2(load_component_names(), load_ref_energies())\n",
    "    for i in data.keys():\n",
    "        data[i] = add_reaction_info_from_h5(data[i])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "\n",
    "data = make_reactions_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cbf693f-e977-4bbd-983d-543a94ec2ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'MGAE109',\n",
       " 'Components': array(['C_mgae109', 'H_mgae109', 'CH_mgae109'], dtype='<U20'),\n",
       " 'Coefficients': tensor([ 1.,  1., -1.]),\n",
       " 'Energy': tensor(84.2300),\n",
       " 'Grid': tensor([[6.3204e+01, 6.3213e+01, 1.9346e+00,  ..., 1.9352e+00, 7.5028e+00,\n",
       "          3.8268e-03],\n",
       "         [6.3204e+01, 6.3213e+01, 1.6335e+02,  ..., 1.6340e+02, 7.8221e+00,\n",
       "          3.2312e-01],\n",
       "         [6.3201e+01, 6.3210e+01, 2.1850e+03,  ..., 2.1857e+03, 1.1821e+01,\n",
       "          4.3224e+00],\n",
       "         ...,\n",
       "         [4.8742e-04, 3.2433e-04, 9.2476e-07,  ..., 5.0238e-07, 2.6551e-04,\n",
       "          1.9790e-04],\n",
       "         [6.3506e-04, 4.3839e-04, 1.5955e-06,  ..., 9.3007e-07, 3.5282e-04,\n",
       "          2.7110e-04],\n",
       "         [4.8742e-04, 3.2433e-04, 9.2476e-07,  ..., 5.0238e-07, 2.6551e-04,\n",
       "          1.9790e-04]]),\n",
       " 'Weights': tensor([2.5717e-17, 9.9780e-15, 3.2611e-13,  ..., 2.6018e-02, 2.2653e-02,\n",
       "         2.6018e-02]),\n",
       " 'Densities': tensor([[6.3204e+01, 6.3213e+01],\n",
       "         [6.3204e+01, 6.3213e+01],\n",
       "         [6.3201e+01, 6.3210e+01],\n",
       "         ...,\n",
       "         [4.8742e-04, 3.2433e-04],\n",
       "         [6.3506e-04, 4.3839e-04],\n",
       "         [4.8742e-04, 3.2433e-04]]),\n",
       " 'HF_energies': tensor([-32.6318,  -0.1908, -32.8681]),\n",
       " 'backsplit_ind': tensor([ 31098.,  64932., 129864.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dbf037-f335-40fc-8ce5-cca32100e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_components(data):\n",
    "    for i in data:\n",
    "        data[i]['Components'] = data[i]['Components'].tobytes()\n",
    "        \n",
    "encode_components(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a25894b-9004-4d97-a139-16ae4137ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87591726, 7])\n"
     ]
    }
   ],
   "source": [
    "y_single = [0.0310907, 0.01554535, \n",
    "            3.72744,   7.06042,\n",
    "            12.9352,   18.0578,\n",
    "            -0.10498,  -0.32500,\n",
    "            0.0310907,  0.01554535,  -1/(6*np.pi**2),\n",
    "            13.0720,    20.1231,      1.06835,\n",
    "            42.7198,   101.578,      11.4813,\n",
    "            -0.409286,  -0.743294,   -0.228344,\n",
    "            1]\n",
    "\n",
    "nconstants = len(y_single)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "device\n",
    "\n",
    "\n",
    "all_grid_data = data[0]['Grid']\n",
    "for i in range(len(data)-1):\n",
    "    all_grid_data = torch.cat([all_grid_data, data[i]['Grid']])\n",
    "print(all_grid_data.shape)\n",
    "\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "stdscaler.fit(np.array(all_grid_data))\n",
    "\n",
    "for i in data:\n",
    "    data[i]['Grid'] = torch.Tensor(stdscaler.transform(data[i]['Grid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0fe30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        self.data[i].pop('Database', None)\n",
    "\n",
    "        return self.data[0], y_single\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.keys())\n",
    "\n",
    "\n",
    "train_set = Dataset(data=data)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set,\n",
    "                                               batch_size=1,\n",
    "                                               num_workers=1,\n",
    "                                               pin_memory=True,\n",
    "                                               shuffle=True)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3424dc36-9e76-41ea-bea5-ae98fe9dfbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.frombuffer(X_batch['Components'][0], dtype='<U20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7eab92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.reset()\n",
    "# torch.cuda.empty_cache()\n",
    "# del X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5683c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPUtil import showUtilization as gpu_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ec4ebf-9e04-4a1d-89aa-96b6862278f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, train_dataloader, n_epochs=2):\n",
    "    \n",
    "    torch.set_printoptions(precision=5)\n",
    "    \n",
    "    train_loss_mse = []\n",
    "    train_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Epoch', epoch+1)\n",
    "        # train\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        train_mse_losses_per_epoch = []\n",
    "        train_mae_losses_per_epoch = []\n",
    "        \n",
    "        progress_bar = tqdm(train_dataloader)\n",
    "\n",
    "        # gradscaler = GradScaler()\n",
    "        for i, (X_batch, y_batch) in enumerate(progress_bar):\n",
    "            # print(np.frombuffer(X_batch['Components'][0], dtype='<U20'), X_batch['Grid'][0].shape)\n",
    "\n",
    "            X_batch = X_batch['Grid'][0].to(device, non_blocking=True)\n",
    "            y_batch = torch.tile(torch.Tensor(y_batch), [X_batch.shape[0],1]).to(device, non_blocking=True)\n",
    "            # with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            MAE = mean_absolute_error(predictions.cpu().detach(), y_batch.cpu().detach())\n",
    "            MSE = loss.item()\n",
    "            train_mse_losses_per_epoch.append(MSE)\n",
    "            train_mae_losses_per_epoch.append(MAE)\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix(MAE = MAE, MSE = MSE)\n",
    "\n",
    "            del X_batch, y_batch, predictions, loss, MAE, MSE\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))\n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "        \n",
    "        print(f'train MSE Loss = {train_loss_mse[epoch]:.8f}')\n",
    "        print(f'train MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "        \n",
    "    return train_loss_mse, train_loss_mae, predictions[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4a42f6-a9ba-49da-8b6e-7098c1e254c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_2_256(DFT='SVWN').to(device)\n",
    "# model.load_state_dict(torch.load('predoptimized_3.param'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8897c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 400, 700, 1000], gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59eff639-e8f9-44b8-bfa8-57a763eb049d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/267 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [00:42<00:00,  6.35it/s, MAE=0.778, MSE=4.25]\n",
      "  0%|          | 0/267 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 107.99707187\n",
      "train MAE Loss = 2.67343998\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [00:46<00:00,  5.77it/s, MAE=0.689, MSE=3.51]\n",
      "  0%|          | 0/267 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 3.79537282\n",
      "train MAE Loss = 0.72444433\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [00:45<00:00,  5.86it/s, MAE=0.64, MSE=3.15] \n",
      "  0%|          | 0/267 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 3.29507779\n",
      "train MAE Loss = 0.66153526\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/267 [00:00<?, ?it/s, MAE=0.64, MSE=3.14]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcba845c5e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/danis/ML/ML_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/danis/ML/ML_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1445, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      " 27%|██▋       | 73/267 [00:11<00:32,  6.05it/s, MAE=0.628, MSE=3.07]"
     ]
    }
   ],
   "source": [
    "train_loss_mse, train_loss_mae, preds = train(model, criterion, optimizer, \n",
    "                                              scheduler, train_dataloader, n_epochs=5)\n",
    "\n",
    "# print(train_loss_mse, train_loss_mae, test_loss_mse, test_loss_mae)\n",
    "# print('predicted coef', '\\n', preds)\n",
    "# print('exact coef', '\\n', np.array(y_single))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066d10b7-e877-4f06-ab5f-ca7270cd29da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  3 22:17:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   43C    P8    13W /  N/A |     23MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2518      G   /usr/bin/gnome-shell                2MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000eccb-ba5b-4f74-b71f-bab526adb440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('ML_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "1be0b9c33878e6644d545b09300b0d1acdcb9b85e0a2f17cbe61dcb3e9601fd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
