{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 964 ms, sys: 271 ms, total: 1.24 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import copy\n",
    "from torch import nn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from NN_models import NN_2_256, NN_8_256, NN_8_64, test\n",
    "from dataset import make_reactions_dict\n",
    "from reaction_energy_calculation import calculate_reaction_energy\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    # seed everything\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 s, sys: 7.02 s, total: 25.5 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# make a single dictionary from the whole dataset\n",
    "data = make_reactions_dict(path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'MGAE109',\n",
       " 'Components': array(['H_mgae109', 'H2_mgae109'], dtype='<U20'),\n",
       " 'Coefficients': tensor([ 2., -1.]),\n",
       " 'Energy': tensor(109.4900),\n",
       " 'Grid': tensor([[ -1.1678, -16.1181, -16.0818,  ..., -16.1181, -16.1033, -16.1181],\n",
       "         [ -1.1678, -16.1181, -14.7017,  ..., -16.1181, -15.3051, -16.1181],\n",
       "         [ -1.1678, -16.1181, -12.3610,  ..., -16.1181, -13.2385, -16.1181],\n",
       "         ...,\n",
       "         [ -8.0004,  -8.0004, -14.2658,  ..., -14.2658,  -8.5148,  -8.5148],\n",
       "         [ -7.7005,  -7.7005, -13.7295,  ..., -13.7295,  -8.2041,  -8.2041],\n",
       "         [ -8.0004,  -8.0004, -14.2658,  ..., -14.2658,  -8.5148,  -8.5148]]),\n",
       " 'Weights': tensor([2.5717e-17, 9.9780e-15, 3.2611e-13,  ..., 2.6055e-02, 2.2680e-02,\n",
       "         2.6055e-02]),\n",
       " 'Densities': tensor([[0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         ...,\n",
       "         [0.0003, 0.0003],\n",
       "         [0.0005, 0.0005],\n",
       "         [0.0003, 0.0003]]),\n",
       " 'Gradients': tensor([[3.6975e-09, 3.6975e-09, 0.0000e+00],\n",
       "         [3.1224e-07, 3.1224e-07, 0.0000e+00],\n",
       "         [4.1824e-06, 4.1824e-06, 0.0000e+00],\n",
       "         ...,\n",
       "         [5.3741e-07, 2.1497e-06, 5.3741e-07],\n",
       "         [9.8983e-07, 3.9593e-06, 9.8983e-07],\n",
       "         [5.3741e-07, 2.1497e-06, 5.3741e-07]]),\n",
       " 'HF_energies': tensor([-0.1908, -0.4750]),\n",
       " 'backsplit_ind': tensor([ 33834., 101502.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[73] # take the easiest reaction H2 = 2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_keys(data):\n",
    "    # turns reaction_data dict keys names into numbers\n",
    "    l = len(data)\n",
    "    keys = data.keys()\n",
    "    data_new = {}\n",
    "    for i, key in zip(range(l), keys):\n",
    "        data_new[i] = data[key]\n",
    "    return data_new\n",
    "\n",
    "\n",
    "def train_split(data, test_size, shuffle=False):\n",
    "    # returns train and test reaction dictionaries\n",
    "    if shuffle:\n",
    "        keys = list(data.keys())\n",
    "        random.shuffle(keys)\n",
    "        for i in keys:\n",
    "            data[keys[i]] = data[i]\n",
    "\n",
    "    train, test = dict(), dict()\n",
    "    border = round(len(data.keys()) * (1 - test_size))\n",
    "    for i in range(len(data.keys())):\n",
    "        if i <= border:\n",
    "            train[i] = data[i]\n",
    "        else:\n",
    "            test[i] = data[i]\n",
    "    return rename_keys(train), rename_keys(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "data_train, data_test = train_split(copy.deepcopy(data), test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([73905233, 7])\n"
     ]
    }
   ],
   "source": [
    "#standard scaler\n",
    "lst = []\n",
    "for i in range(len(data_train)):\n",
    "    lst.append(data_train[i]['Grid'])\n",
    "\n",
    "train_grid_data = torch.cat(lst)\n",
    "print(train_grid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 s, sys: 1.39 s, total: 13 s\n",
      "Wall time: 13.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "stdscaler = StandardScaler()\n",
    "stdscaler.fit(np.array(train_grid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.74 s, sys: 80.8 ms, total: 4.82 s\n",
      "Wall time: 4.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for data_t in (data_train, data_test):\n",
    "    for i in range(len(data_t)):\n",
    "        data_t[i]['Grid'] = torch.Tensor(stdscaler.transform(data_t[i]['Grid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'NCCE31',\n",
       " 'Components': array(['HCl-HCl_ncce31', 'HCl_ncce31'], dtype='<U20'),\n",
       " 'Coefficients': tensor([-1.,  2.]),\n",
       " 'Energy': tensor(2.0100),\n",
       " 'Grid': tensor([[1.8193, 1.8079, 1.9052,  ..., 1.9413, 1.8151, 1.8091],\n",
       "         [1.8193, 1.8079, 2.0157,  ..., 2.0501, 1.8209, 1.8145],\n",
       "         [1.8193, 1.8078, 2.0798,  ..., 2.1132, 1.8580, 1.8490],\n",
       "         ...,\n",
       "         [1.1998, 1.2391, 1.2329,  ..., 1.2795, 1.1805, 1.2183],\n",
       "         [1.2115, 1.2498, 1.2455,  ..., 1.2918, 1.1918, 1.2289],\n",
       "         [1.1998, 1.2391, 1.2329,  ..., 1.2795, 1.1805, 1.2183]]),\n",
       " 'Weights': tensor([2.5717e-17, 9.9780e-15, 3.2611e-13,  ..., 2.5979e-02, 2.2624e-02,\n",
       "         2.5979e-02]),\n",
       " 'Densities': tensor([[1.5987e+03, 1.5987e+03],\n",
       "         [1.5986e+03, 1.5986e+03],\n",
       "         [1.5977e+03, 1.5977e+03],\n",
       "         ...,\n",
       "         [2.7319e-04, 2.7319e-04],\n",
       "         [3.6636e-04, 3.6636e-04],\n",
       "         [2.7319e-04, 2.7319e-04]]),\n",
       " 'Gradients': tensor([[2.1993e+05, 8.7972e+05, 2.1993e+05],\n",
       "         [1.8339e+07, 7.3357e+07, 1.8339e+07],\n",
       "         [2.3826e+08, 9.5303e+08, 2.3826e+08],\n",
       "         ...,\n",
       "         [3.5673e-07, 1.4269e-06, 3.5673e-07],\n",
       "         [6.5521e-07, 2.6209e-06, 6.5521e-07],\n",
       "         [3.5673e-07, 1.4269e-06, 3.5673e-07]]),\n",
       " 'HF_energies': tensor([-864.4767, -432.2389]),\n",
       " 'backsplit_ind': tensor([127368., 191052.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 2.38 s, total: 4.19 s\n",
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pickle\n",
    "# with open('checkpoints/data_train.pickle', 'wb') as f:\n",
    "#     pickle.dump(data_train, f)\n",
    "\n",
    "with open('checkpoints/data_train.pickle', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "with open('checkpoints/data_test.pickle', 'rb') as f:\n",
    "    data_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        # i = 1\n",
    "        self.data[i].pop('Database', None)\n",
    "\n",
    "        return self.data[i], self.data[i]['Energy']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.keys())\n",
    "\n",
    "\n",
    "train_set = Dataset(data=data_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, \n",
    "                                               batch_size=None,\n",
    "                                               num_workers=1,\n",
    "                                               pin_memory=True,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_set = Dataset(data=data_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, \n",
    "                                              batch_size=None,\n",
    "                                              num_workers=1,\n",
    "                                              pin_memory=True,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "\n",
    "# model = NN_2_256(nconstants=21, DFT='SVWN').to(device)\n",
    "\n",
    "model = NN_2_256(nconstants=27, DFT='PBE').to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('predopt/PBE_2_256_test.param', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'NN_models' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/NN_models.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import NN_models\n",
    "reload(NN_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 572 µs, sys: 0 ns, total: 572 µs\n",
      "Wall time: 584 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "true_constants_SVWN = [0.0310907, 0.01554535, \n",
    "            3.72744,   7.06042,\n",
    "            12.9352,   18.0578,\n",
    "            -0.10498,  -0.32500,\n",
    "            0.0310907,  0.01554535,  -1/(6*np.pi**2),\n",
    "            13.0720,    20.1231,      1.06835,\n",
    "            42.7198,   101.578,      11.4813,\n",
    "            -0.409286,  -0.743294,   -0.228344,\n",
    "            1]\n",
    "\n",
    "true_constants_PBE = torch.Tensor([[0.06672455060314922,\n",
    "       (1 - torch.log(torch.Tensor([2])))/(torch.pi**2),\n",
    "       1.709921,\n",
    "       7.5957, 14.1189, 10.357,\n",
    "       3.5876, 6.1977, 3.6231,\n",
    "       1.6382, 3.3662,  0.88026,\n",
    "       0.49294, 0.62517, 0.49671,\n",
    "       1,  1,  1,\n",
    "       0.031091, 0.015545, 0.016887,\n",
    "       0.21370,  0.20548,  0.11125,\n",
    "       -3/8*(3/torch.pi)**(1/3)*4**(2/3),\n",
    "       0.8040,\n",
    "       0.2195149727645171]])\n",
    "\n",
    "\n",
    "y_single = true_constants_PBE\n",
    "\n",
    "class DatasetPredopt(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        i = 0\n",
    "        self.data[i].pop('Database', None)\n",
    "\n",
    "        return self.data[i], y_single \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.keys())\n",
    "\n",
    "\n",
    "train_predopt_set = DatasetPredopt(data=data)\n",
    "train_predopt_dataloader = torch.utils.data.DataLoader(train_predopt_set,\n",
    "                                                       batch_size=None,\n",
    "                                                       num_workers=1,\n",
    "                                                       pin_memory=True,\n",
    "                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940705db9e314d2b882772487c4a8b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 0.13953993\n",
      "train MAE Loss = 0.07829372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.13953992913463223], [0.07829372])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predopt import predopt\n",
    "\n",
    "\n",
    "predopt(model, criterion, optimizer, train_predopt_dataloader, device, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'predopt/PBE_2_256_test.param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "log_file_path = 'log/epoch_training.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(log_file_path):\n",
    "    os.remove(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, test_loader, n_epochs=20, accum_iter=4, verbose=False):\n",
    "    train_loss_mae = []\n",
    "    train_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        # train\n",
    "        \n",
    "        model.train()\n",
    "        progress_bar_train = tqdm(train_loader)\n",
    "        train_mae_losses_per_epoch = []\n",
    "        train_mse_losses_per_epoch = []\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(progress_bar_train):\n",
    "            \n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch_grid)\n",
    "            # print(predictions)\n",
    "            # predictions = torch.tile(torch.Tensor(true_constants_PBE), [X_batch_grid.shape[0],1]).to(device, non_blocking=True)\n",
    "            # print(predictions)\n",
    "            # print(torch.max(torch.abs(predictions)))\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung='GGA', dft='PBE')\n",
    "            if verbose:\n",
    "                print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f}\")\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "\n",
    "            # loss_accumulation\n",
    "            loss = loss / accum_iter\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(train_loader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                MSE = loss.item()\n",
    "                MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "                train_mse_losses_per_epoch.append(MSE)\n",
    "                train_mae_losses_per_epoch.append(MAE)\n",
    "                progress_bar_train.set_postfix(MSE = MSE, MAE = MAE)\n",
    "\n",
    "                \n",
    "                with open(log_file_path, 'a') as f:\n",
    "                    f.write(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\\n\")\n",
    "                    # f.write(f\"{preds}\\n\")\n",
    "                    \n",
    "                del MAE, MSE\n",
    "            \n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # gpu_usage()\n",
    "        \n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))        \n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'train MSE Loss = {train_loss_mse[epoch]:.8f} MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "\n",
    "\n",
    "        \n",
    "        #test\n",
    "        # progress_bar_test = tqdm(test_loader)\n",
    "        model.eval()\n",
    "        test_mae_losses_per_epoch = []\n",
    "        test_mse_losses_per_epoch = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "                predictions = model(X_batch_grid)\n",
    "                reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung='GGA', dft='PBE')\n",
    "                loss = criterion(reaction_energy, y_batch)\n",
    "                MSE = loss.item()\n",
    "                MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "                progress_bar_train.set_postfix(MAE = MAE)\n",
    "                test_mse_losses_per_epoch.append(MSE)\n",
    "                test_mae_losses_per_epoch.append(MAE)\n",
    "                \n",
    "                with open(log_file_path, 'a') as f:\n",
    "                    f.write(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\\n\")\n",
    "                \n",
    "                del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        test_loss_mse.append(np.mean(test_mse_losses_per_epoch))\n",
    "        test_loss_mae.append(np.mean(test_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'test MSE Loss = {test_loss_mse[epoch]:.8f} MAE Loss = {test_loss_mae[epoch]:.8f}')\n",
    "\n",
    "    return train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PBE' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/PBE.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import PBE\n",
    "import reaction_energy_calculation\n",
    "import utils\n",
    "import NN_models\n",
    "reload(NN_models)\n",
    "reload(utils)\n",
    "reload(reaction_energy_calculation)\n",
    "reload(PBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a57d4756a74c1ab64fa4203db83294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 2327.80249714 MAE Loss = 46.74373307\n",
      "res_A is inf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "infinity detected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss_mae \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, n_epochs, accum_iter, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m X_batch_grid, y_batch \u001b[38;5;241m=\u001b[39m X_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(X_batch_grid)\n\u001b[0;32m---> 71\u001b[0m reaction_energy \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_reaction_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrung\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGGA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPBE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(reaction_energy, y_batch)\n\u001b[1;32m     73\u001b[0m MSE \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/reaction_energy_calculation.py:68\u001b[0m, in \u001b[0;36mcalculate_reaction_energy\u001b[0;34m(reaction, constants, device, rung, dft)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_reaction_energy\u001b[39m(reaction, constants, device, rung, dft):\n\u001b[0;32m---> 68\u001b[0m     local_energies \u001b[38;5;241m=\u001b[39m \u001b[43mget_local_energies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreaction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrung\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# print(local_energies)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_energies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocal_energies\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/reaction_energy_calculation.py:21\u001b[0m, in \u001b[0;36mget_local_energies\u001b[0;34m(reaction, constants, device, rung, dft)\u001b[0m\n\u001b[1;32m     19\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m (reaction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradients\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dft \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m         local_energies \u001b[38;5;241m=\u001b[39m \u001b[43mF_PBE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdensities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m calc_reaction_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocal_energies\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m local_energies\n\u001b[1;32m     24\u001b[0m calc_reaction_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDensities\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m densities\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/PBE.py:194\u001b[0m, in \u001b[0;36mF_PBE\u001b[0;34m(rho, sigmas, c_arr)\u001b[0m\n\u001b[1;32m    192\u001b[0m rs, z \u001b[38;5;241m=\u001b[39m rs_z_calc(rho)\n\u001b[1;32m    193\u001b[0m xs0, xs1, xt \u001b[38;5;241m=\u001b[39m xs_xt_calc(rho, sigmas)\n\u001b[0;32m--> 194\u001b[0m res_energy \u001b[38;5;241m=\u001b[39m PBE_X(rs, z, xt, xs0, xs1, c_arr) \u001b[38;5;241m+\u001b[39m \u001b[43mPBE_C\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m catch_nan(res_energy\u001b[38;5;241m=\u001b[39mres_energy)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_energy\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/PBE.py:131\u001b[0m, in \u001b[0;36mPBE_C\u001b[0;34m(rs, z, xt, c_arr)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPBE_C\u001b[39m(rs, z, xt, c_arr):\n\u001b[0;32m--> 131\u001b[0m     res_PBE_C \u001b[38;5;241m=\u001b[39m f_pw(rs, z, c_arr) \u001b[38;5;241m+\u001b[39m \u001b[43mfH\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     catch_nan(res_PBE_C\u001b[38;5;241m=\u001b[39mres_PBE_C)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res_PBE_C\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/PBE.py:124\u001b[0m, in \u001b[0;36mfH\u001b[0;34m(rs, z, t, c_arr)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfH\u001b[39m(rs, z, t, c_arr):\n\u001b[0;32m--> 124\u001b[0m     log \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mf2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    125\u001b[0m     res_fH \u001b[38;5;241m=\u001b[39m c_arr[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mmphi(z)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mlog\n\u001b[1;32m    126\u001b[0m     catch_nan(res_fH\u001b[38;5;241m=\u001b[39mres_fH, log\u001b[38;5;241m=\u001b[39mlog)\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/PBE.py:116\u001b[0m, in \u001b[0;36mf2\u001b[0;34m(rs, z, t, c_arr)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf2\u001b[39m(rs, z, t, c_arr):\n\u001b[1;32m    115\u001b[0m     eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-29\u001b[39m\n\u001b[0;32m--> 116\u001b[0m     f1_ \u001b[38;5;241m=\u001b[39m \u001b[43mf1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     A_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mA(rs, z, t, c_arr)\n\u001b[1;32m    118\u001b[0m     res_f2 \u001b[38;5;241m=\u001b[39m c_arr[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mf1_\u001b[38;5;241m/\u001b[39m(c_arr[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m(A_1)\u001b[38;5;241m*\u001b[39mf1_ \u001b[38;5;241m+\u001b[39m eps)\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/PBE.py:109\u001b[0m, in \u001b[0;36mf1\u001b[0;34m(rs, z, t, c_arr)\u001b[0m\n\u001b[1;32m    107\u001b[0m BB \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# flexibility of A(rs, z, t)*t**4 term \\ constant \\ 1 or 0\u001b[39;00m\n\u001b[1;32m    108\u001b[0m t2 \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 109\u001b[0m res_f1 \u001b[38;5;241m=\u001b[39m t2 \u001b[38;5;241m+\u001b[39m BB\u001b[38;5;241m*\u001b[39m\u001b[43mA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mt2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    110\u001b[0m catch_nan(res_f1\u001b[38;5;241m=\u001b[39mres_f1)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_f1\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/PBE.py:102\u001b[0m, in \u001b[0;36mA\u001b[0;34m(rs, z, t, c_arr)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mA\u001b[39m(rs, z, t, c_arr):\n\u001b[1;32m    101\u001b[0m     res_A \u001b[38;5;241m=\u001b[39m c_arr[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m(c_arr[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m(torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mf_pw(rs, z, c_arr)\u001b[38;5;241m/\u001b[39m(c_arr[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mmphi(z)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcatch_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_A\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res_A\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/utils.py:24\u001b[0m, in \u001b[0;36mcatch_nan\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_printoptions(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     23\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(v, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfinity detected\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: infinity detected"
     ]
    }
   ],
   "source": [
    "train_loss_mae = train(model, criterion, optimizer,\n",
    "                              train_dataloader,\n",
    "                              test_dataloader, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dft(train_loader, test_loader, c_arr, criterion, rung, dft, verbose=False, n_epochs=1):\n",
    "    train_loss_mae = []\n",
    "    train_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        # train\n",
    "        \n",
    "        progress_bar_train = tqdm(train_loader)\n",
    "        train_mae_losses_per_epoch = []\n",
    "        train_mse_losses_per_epoch = []\n",
    "        for X_batch, y_batch in progress_bar_train:\n",
    "            # print(f\"{X_batch['Components']}\")\n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            # print(torch.tile(c_arr, [X_batch_grid.shape[0],1]))\n",
    "            predictions = torch.tile(c_arr, [X_batch_grid.shape[0],1]).to(device)\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung, dft)\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            MSE = loss.item()\n",
    "            MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "            train_mse_losses_per_epoch.append(MSE)\n",
    "            train_mae_losses_per_epoch.append(MAE)\n",
    "            progress_bar_train.set_postfix(MSE = MSE, MAE = MAE)\n",
    "            if verbose:\n",
    "                print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\")\n",
    "\n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))        \n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'train MSE Loss = {train_loss_mse[epoch]:.8f} MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "\n",
    "\n",
    "        \n",
    "        #test\n",
    "        # progress_bar_test = tqdm(test_loader)\n",
    "        test_mae_losses_per_epoch = []\n",
    "        test_mse_losses_per_epoch = []\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            # print(f\"{X_batch['Components']}\")\n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            predictions = torch.tile(c_arr, (X_batch_grid.shape[0],1)).to(device)\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung, dft)\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            MSE = loss.item()\n",
    "            MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "            # progress_bar_train.set_postfix(MAE = MAE)\n",
    "            test_mse_losses_per_epoch.append(MSE)\n",
    "            test_mae_losses_per_epoch.append(MAE)\n",
    "            if verbose:\n",
    "                print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\")\n",
    "            \n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "                \n",
    "        test_loss_mse.append(np.mean(test_mse_losses_per_epoch))\n",
    "        test_loss_mae.append(np.mean(test_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'test MSE Loss = {test_loss_mse[epoch]:.8f} MAE Loss = {test_loss_mae[epoch]:.8f}')\n",
    "\n",
    "    return train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import NN_models\n",
    "reload(NN_models)\n",
    "from NN_models import NN_2_256, NN_8_256, NN_8_64\n",
    "# import SVWN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089359892188457b95e5ae59d2b798f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 7856.53110129 MAE Loss = 45.47375717\n",
      "test MSE Loss = 4927.27600202 MAE Loss = 35.76542641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[45.47375716634615]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_constants_SVWN = torch.Tensor([0.0310907, 0.01554535, \n",
    "                3.72744,   7.06042,\n",
    "                12.9352,   18.0578,\n",
    "                -0.10498,  -0.32500,\n",
    "                0.0310907,  0.01554535,  -1/(6*torch.pi**2),\n",
    "                13.0720,    20.1231,      1.06835,\n",
    "                42.7198,   101.578,      11.4813,\n",
    "                -0.409286,  -0.743294,   -0.228344,\n",
    "                1])\n",
    "\n",
    "true_constants_PBE = torch.Tensor([[0.06672455060314922,\n",
    "       (1 - torch.log(torch.Tensor([2])))/(torch.pi**2),\n",
    "       1.709920934161365617563962776245,\n",
    "       7.5957, 14.1189, 10.357,\n",
    "       3.5876, 6.1977, 3.6231,\n",
    "       1.6382, 3.3662,  0.88026,\n",
    "       0.49294, 0.62517, 0.49671,\n",
    "       1,  1,  1,\n",
    "       0.031091, 0.015545, 0.016887,\n",
    "       0.21370,  0.20548,  0.11125,\n",
    "       -3/8*(3/torch.pi)**(1/3)*4**(2/3),\n",
    "       0.8040,\n",
    "       0.2195149727645171]])\n",
    "\n",
    "# true_constants\n",
    "\n",
    "test_dft(train_dataloader, test_dataloader, true_constants_PBE, criterion, rung='GGA', dft='PBE', verbose=False)\n",
    "# test_dft(train_dataloader, test_dataloader, true_constants_SVWN, criterion, rung='LDA', dft='SVWN3', verbose=False)\n",
    "\n",
    "\n",
    "# PBE 45.47375717 35.76542641\n",
    "# LDA 32.63222432 26.81526929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs0 = torch.load('log/xs0.pt')\n",
    "xs1 = torch.load('log/xs1.pt')\n",
    "xt = torch.load('log/xt.pt')\n",
    "rho = torch.load('log/rho.pt')\n",
    "sigmas = torch.load('log/sigmas.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'MGAE109',\n",
       " 'Components': array(['H_mgae109', 'H2_mgae109'], dtype='<U20'),\n",
       " 'Coefficients': tensor([ 2., -1.]),\n",
       " 'Energy': tensor(109.4899978637695312500000000),\n",
       " 'Grid': tensor([[ -1.1677658557891845703125000, -16.1180953979492187500000000,\n",
       "          -16.0817871093750000000000000,  ...,\n",
       "          -16.1180953979492187500000000, -16.1033458709716796875000000,\n",
       "          -16.1180953979492187500000000],\n",
       "         [ -1.1677658557891845703125000, -16.1180953979492187500000000,\n",
       "          -14.7016716003417968750000000,  ...,\n",
       "          -16.1180953979492187500000000, -15.3050699234008789062500000,\n",
       "          -16.1180953979492187500000000],\n",
       "         [ -1.1677662134170532226562500, -16.1180953979492187500000000,\n",
       "          -12.3609895706176757812500000,  ...,\n",
       "          -16.1180953979492187500000000, -13.2384977340698242187500000,\n",
       "          -16.1180953979492187500000000],\n",
       "         ...,\n",
       "         [ -8.0003814697265625000000000,  -8.0003814697265625000000000,\n",
       "          -14.2658472061157226562500000,  ...,\n",
       "          -14.2658472061157226562500000,  -8.5147609710693359375000000,\n",
       "           -8.5147609710693359375000000],\n",
       "         [ -7.7005100250244140625000000,  -7.7005100250244140625000000,\n",
       "          -13.7294902801513671875000000,  ...,\n",
       "          -13.7294902801513671875000000,  -8.2040796279907226562500000,\n",
       "           -8.2040796279907226562500000],\n",
       "         [ -8.0003814697265625000000000,  -8.0003814697265625000000000,\n",
       "          -14.2658472061157226562500000,  ...,\n",
       "          -14.2658472061157226562500000,  -8.5147609710693359375000000,\n",
       "           -8.5147609710693359375000000]]),\n",
       " 'Weights': tensor([2.5717263619955344411058262e-17, 9.9780100021730315507095810e-15,\n",
       "         3.2611004283263078651344813e-13,  ...,\n",
       "         2.6054665446281433105468750e-02, 2.2679904475808143615722656e-02,\n",
       "         2.6054665446281433105468750e-02]),\n",
       " 'Densities': tensor([[0.3110610246658325195312500, 0.0000000000000000000000000],\n",
       "         [0.3110610246658325195312500, 0.0000000000000000000000000],\n",
       "         [0.3110609054565429687500000, 0.0000000000000000000000000],\n",
       "         ...,\n",
       "         [0.0003352346247993409633636, 0.0003352346247993409633636],\n",
       "         [0.0004524962278082966804504, 0.0004524962278082966804504],\n",
       "         [0.0003352346247993409633636, 0.0003352346247993409633636]]),\n",
       " 'Gradients': tensor([[3.6975302819541866483632475e-09, 3.6975302819541866483632475e-09,\n",
       "          0.0000000000000000000000000e+00],\n",
       "         [3.1223541441249835770577192e-07, 3.1223541441249835770577192e-07,\n",
       "          0.0000000000000000000000000e+00],\n",
       "         [4.1824300751613918691873550e-06, 4.1824300751613918691873550e-06,\n",
       "          0.0000000000000000000000000e+00],\n",
       "         ...,\n",
       "         [5.3741337069368455559015274e-07, 2.1496534827747382223606110e-06,\n",
       "          5.3741337069368455559015274e-07],\n",
       "         [9.8982786767010111361742020e-07, 3.9593114706804044544696808e-06,\n",
       "          9.8982786767010111361742020e-07],\n",
       "         [5.3741337069368455559015274e-07, 2.1496534827747382223606110e-06,\n",
       "          5.3741337069368455559015274e-07]]),\n",
       " 'HF_energies': tensor([-0.1908379942178726196289062, -0.4749920070171356201171875]),\n",
       " 'backsplit_ind': tensor([ 33834., 101502.])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PBE' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/PBE.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import PBE\n",
    "import reaction_energy_calculation\n",
    "import utils\n",
    "import NN_models\n",
    "reload(NN_models)\n",
    "reload(utils)\n",
    "reload(reaction_energy_calculation)\n",
    "reload(PBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0574636682868003845214844, -0.0574636720120906829833984,\n",
      "        -0.0574636645615100860595703,  ...,\n",
      "        -0.0582121163606643676757812, -0.0564256645739078521728516,\n",
      "        -0.0582121163606643676757812], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(82.9000549316406250000000000, device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_reaction_energy(data[73], torch.tile(true_constants_PBE, [data[73]['Grid'].shape[0],1]).to(device), device, rung='GGA', dft='PBE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('checkpoints/calc_reaction_data.pickle', 'rb') as f:\n",
    "    calc_reaction_data = pickle.load(f)\n",
    "with open('checkpoints/reaction.pickle', 'rb') as f:\n",
    "    reaction = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Local_energies': tensor([-0.6879517436027526855468750, -0.6879517436027526855468750,\n",
       "         -0.6879518628120422363281250,  ...,\n",
       "         -0.1652928292751312255859375, -0.1730412542819976806640625,\n",
       "         -0.1652928292751312255859375], device='cuda:0'),\n",
       " 'Densities': tensor([[0.3110610246658325195312500, 0.0000000000000000000000000],\n",
       "         [0.3110610246658325195312500, 0.0000000000000000000000000],\n",
       "         [0.3110609054565429687500000, 0.0000000000000000000000000],\n",
       "         ...,\n",
       "         [0.0003352346247993409633636, 0.0003352346247993409633636],\n",
       "         [0.0004524962278082966804504, 0.0004524962278082966804504],\n",
       "         [0.0003352346247993409633636, 0.0003352346247993409633636]],\n",
       "        device='cuda:0'),\n",
       " 'Weights': tensor([2.5717263619955344411058262e-17, 9.9780100021730315507095810e-15,\n",
       "         3.2611004283263078651344813e-13,  ...,\n",
       "         2.6054665446281433105468750e-02, 2.2679904475808143615722656e-02,\n",
       "         2.6054665446281433105468750e-02], device='cuda:0')}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_reaction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434, device='cuda:0')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs0.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434, device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs1.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434, device='cuda:0')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmas.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 3\n",
    "eps = 1e-29\n",
    "xs1_test = torch.where((sigmas[:,2] < eps) & (rho[:,1] < eps), # last sigma and last rho equal 0\n",
    "                  torch.sqrt(sigmas[:,0])/rho[:,0]**(1 + 1/DIMENSIONS), \n",
    "                  torch.sqrt(sigmas[:,2])/rho[:,1]**(1 + 1/DIMENSIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434, device='cuda:0')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs1_test.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sqrt(sigmas[:,2]))[(torch.sqrt(sigmas[:,0])/rho[:,0]**(1 + 1/DIMENSIONS)).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1302, device='cuda:0')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sigmas[:,2] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434, device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sqrt(sigmas[:,2])/rho[:,1]**(1 + 1/DIMENSIONS)).isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rho[:,1]**(1 + 1/DIMENSIONS)).isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(434, device='cuda:0')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sqrt(sigmas[:,2]))[(torch.sqrt(sigmas[:,2])/rho[:,1]**(1 + 1/DIMENSIONS)).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36,\n",
       "        3.7042367537315712554845936e-36, 3.7042367537315712554845936e-36],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rho[:,1])[(torch.sqrt(sigmas[:,2])/rho[:,1]**(1 + 1/DIMENSIONS)).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([394176])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(63)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_f2.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbeta  = 0.06672455060314922\n",
    "mgamma = (1 - torch.log(torch.Tensor([2])))/(torch.pi**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_f2_new = mbeta*f1_/(mgamma*(A_1)*f1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_1[res_f2.isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0352594852447509765625000, 1.0352596044540405273437500,\n",
       "        1.0352602005004882812500000,  ...,\n",
       "        1.1321227550506591796875000, 1.1538784503936767578125000,\n",
       "        1.1526243686676025390625000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = data[73]['Densities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (densities[:, 0] == 0) & (densities[:, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3110610246658325195312500, 0.0000000000000000000000000],\n",
       "        [0.3110610246658325195312500, 0.0000000000000000000000000],\n",
       "        [0.3110609054565429687500000, 0.0000000000000000000000000],\n",
       "        ...,\n",
       "        [0.0003352346247993409633636, 0.0003352346247993409633636],\n",
       "        [0.0004524962278082966804504, 0.0004524962278082966804504],\n",
       "        [0.0003352346247993409633636, 0.0003352346247993409633636]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densities[torch.logical_not(condition)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_arr = torch.rand([30, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1502285599708557128906250, 0.5830305218696594238281250,\n",
       "        0.5014850497245788574218750, 0.8293408751487731933593750,\n",
       "        0.7447895407676696777343750, 0.5668825507164001464843750,\n",
       "        0.8410924673080444335937500, 0.2260936498641967773437500,\n",
       "        0.0402220487594604492187500, 0.4239581227302551269531250,\n",
       "        0.8237568140029907226562500, 0.7643668055534362792968750,\n",
       "        0.2284420728683471679687500, 0.4776555895805358886718750,\n",
       "        0.7411935925483703613281250, 0.0978116989135742187500000,\n",
       "        0.6150720119476318359375000, 0.6752546429634094238281250,\n",
       "        0.4563951492309570312500000, 0.6024737954139709472656250,\n",
       "        0.9505222439765930175781250, 0.9367821812629699707031250,\n",
       "        0.3959974646568298339843750, 0.3070790767669677734375000,\n",
       "        0.1345978379249572753906250, 0.5169637799263000488281250,\n",
       "        0.8828852772712707519531250, 0.5466136932373046875000000,\n",
       "        0.5866019725799560546875000, 0.4392346739768981933593750])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_arr[:, 21:24][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_PBE = torch.Tensor([[0.06672455060314922,\n",
    "(1 - torch.log(torch.Tensor([2])))/(torch.pi**2),\n",
    "1.709921,\n",
    "7.5957, 14.1189, 10.357,\n",
    "3.5876, 6.1977, 3.6231,\n",
    "1.6382, 3.3662,  0.88026,\n",
    "0.49294, 0.62517, 0.49671,\n",
    "1,  1,  1,\n",
    "0.031091, 0.015545, 0.016887,\n",
    "0.21370,  0.20548,  0.11125,\n",
    "-3/8*(3/torch.pi)**(1/3)*4**(2/3),\n",
    "0.8040,\n",
    "0.2195149727645171]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs1 = torch.load('xs1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33834, device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs1.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5244732648134231567382812e-03, 5.0763797014951705932617188e-02,\n",
       "        1.8567425012588500976562500e-01,  ...,\n",
       "        3.1317285537719726562500000e+01, 1.0731460571289062500000000e+01,\n",
       "        1.1295479774475097656250000e+01], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.11 [python-pytorch1_11]",
   "language": "python",
   "name": "conda-env-python-pytorch1_11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5e5bb8c7f59d999df07168cdddfd96f8fceb1d4deaee65f2787e1aa74655cd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
