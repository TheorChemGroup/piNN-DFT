{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/python/envs/pytorch1_11/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random\n",
    "# from tqdm.auto import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "from SVWN3 import f_svwn3\n",
    "from SVWN3_njit import f_svwn3_njit\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "from NN_models import NN_2_256, NN_8_256, NN_8_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref(x, y):\n",
    "    ''' \n",
    "    returns reference energies for points of a reaction grid from Reference_data.csv\n",
    "    '''\n",
    "    hartree2kcal = 627.5095\n",
    "    with open(\"Reference_data.csv\", newline='', encoding='cp1251') as csvfile:\n",
    "        ref_file = csv.reader(csvfile, delimiter=\",\")\n",
    "        k = 1\n",
    "        if y == 391:\n",
    "            k = hartree2kcal\n",
    "        ref = []\n",
    "        for n, i in enumerate(ref_file):\n",
    "            if x <= n + 1 <= y:\n",
    "                ref.append((i[0], float(i[2]) * k))\n",
    "\n",
    "        return ref\n",
    "\n",
    "def load_ref_energies():\n",
    "    '''Returns {db_name: [equation, energy]}'''\n",
    "    ref_e = { # Получение референсных энергий\n",
    "        \"MGAE109\":ref(8, 116),\n",
    "        \"IP13\":ref(155, 167),\n",
    "        \"EA13\":ref(180, 192),\n",
    "        \"PA8\":ref(195, 202),\n",
    "        \"DBH76\":ref(251, 288) + ref(291, 328),\n",
    "        \"NCCE31\":ref(331, 361),\n",
    "        \"ABDE4\":ref(206, 209),\n",
    "        # \"AE17\":ref(375, 391),\n",
    "        \"pTC13\":ref(232, 234) + ref(237, 241) + ref(244, 248)\n",
    "        } \n",
    "    return ref_e\n",
    "\n",
    "def load_component_names():\n",
    "    '''\n",
    "    Returns {db_name: {id: {'Components': [...], 'Coefficients: [...]'\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "     which is a dictionary with Components and Coefficients data about all reactions\n",
    "    '''\n",
    "    with open(\"total_dataframe_sorted_final.csv\", newline='', encoding='cp1251') as csvfile:\n",
    "        ref_file = csv.reader(csvfile, delimiter=\",\")\n",
    "        ref = dict()\n",
    "        current_database = None\n",
    "        \n",
    "        for n, line in enumerate(ref_file):\n",
    "            line = np.array(line)\n",
    "            if n == 0:\n",
    "                components = np.array(line)\n",
    "            else:\n",
    "                reaction_id = int(line[0])\n",
    "                reaction_database = line[1]\n",
    "                reaction_component_num = np.nonzero(list(map(float, line[2:])))[0] + 2\n",
    "                if reaction_database in ref:\n",
    "                    ref[reaction_database][reaction_id] = {'Components': components[reaction_component_num], 'Coefficients': line[reaction_component_num]}\n",
    "                else: \n",
    "                    ref[reaction_database] = {reaction_id: {'Components': components[reaction_component_num], 'Coefficients': line[reaction_component_num]}}\n",
    "        return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compounds_coefs_energy_v2(reactions, energies):\n",
    "    '''Returns {id: \n",
    "                    {'Components': [...], 'Coefficients: [...]', 'Energy: float', Database: str\n",
    "                                }\n",
    "                            }\n",
    "    which is a dictionaty from load_component_names with Energy information added\n",
    "    '''\n",
    "    data_final = dict()\n",
    "    i = 0\n",
    "    databases = load_ref_energies().keys()\n",
    "    for database in databases:\n",
    "        data = reactions[database]\n",
    "        for reaction in data:\n",
    "            data[reaction]['Energy'] = energies[database][reaction][1]\n",
    "            data_final[i] = {'Database': database,\n",
    "                         'Components': reactions[database][reaction]['Components'].astype(object),\n",
    "                         'Coefficients': reactions[database][reaction]['Coefficients'].astype(np.float64),\n",
    "                         'Energy': energies[database][reaction][1]\n",
    "            \n",
    "        }\n",
    "            i += 1\n",
    "        \n",
    "    return data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h5_names(reaction):\n",
    "    '''reaction must be from the function get_compounds_coefs_energy_v2'''\n",
    "    database_match = {\n",
    "        'MGAE109': 'mgae109',\n",
    "        'IP13': 'ip13',\n",
    "        'EA13': 'ea13',\n",
    "        'PA8': 'pa8',\n",
    "        'DBH76': 'ntbh38',\n",
    "        'NCCE31': 'ncce31',\n",
    "        'ABDE4': 'abde4',\n",
    "        'AE17': 'ae17',\n",
    "        'pTC13': 'ptc13'\n",
    "    }\n",
    "    names = []\n",
    "    for elem in reaction['Components']:\n",
    "        database = database_match[reaction['Database']]\n",
    "        names.append(f'{elem}.h5')\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reaction_info_from_h5(reaction):\n",
    "    '''\n",
    "    reaction must be from get_compounds_coefs_energy_v2\n",
    "    returns merged descriptos array X, integration weights, \n",
    "    a and b densities and indexes for backsplitting\n",
    "    \n",
    "    Adds the following information to the reaction dict using h5 files from the dataset:\n",
    "    Grid : np.array with grid descriptors\n",
    "    Weights : list with integration weights of grid points\n",
    "    Densities : np.array with alpha and beta densities data for grid points\n",
    "    HF_energies : list of Total HF energy (T+V) which needs to be added to E_xc\n",
    "    backsplit_ind: list of indexes where we concatenate molecules' grids\n",
    "    '''\n",
    "    X = np.array([])\n",
    "    backsplit_ind = []\n",
    "    HF_energies = np.array([])\n",
    "    for component_filename in get_h5_names(reaction):\n",
    "        with h5py.File(f'data/{component_filename}', \"r\") as f:\n",
    "            HF_energies = np.append(HF_energies, f[\"ener\"][:][0])\n",
    "            X_raw = np.array(f[\"grid\"][:])\n",
    "            if len(X) == 0:\n",
    "                X = X_raw[:, 3:-1]\n",
    "            else:\n",
    "                X = np.vstack((X, X_raw[:, 3:-1]))\n",
    "            backsplit_ind.append(len(X))\n",
    "    densities = X[:, 1:3]\n",
    "    weights = X[:,0]\n",
    "    X = X[:, 1:]\n",
    "\n",
    "    labels = ['Grid', 'Weights', 'Densities', 'HF_energies', 'backsplit_ind']\n",
    "    values = [X, weights, densities, HF_energies, backsplit_ind]\n",
    "    for label, value in zip(labels, values):\n",
    "        reaction[label] = torch.Tensor(value)\n",
    "\n",
    "    return reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reactions_dict():\n",
    "    '''\n",
    "    Returns a dict like {reaction_id: {*reaction info}} with all info available listed below:\n",
    "    ['Database', 'Components', 'Coefficients', 'Energy', 'Grid', 'Weights', 'Densities', 'HF_energies', 'backsplit_ind']\n",
    "    '''\n",
    "    data = get_compounds_coefs_energy_v2(load_component_names(), load_ref_energies())\n",
    "    for i in data.keys():\n",
    "        data[i] = add_reaction_info_from_h5(data[i])\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_energies(reaction, constants):\n",
    "    calc_reaction_data = {}\n",
    "    densities = reaction['Densities']\n",
    "    local_energies = f_svwn3(densities, constants)\n",
    "    calc_reaction_data['Local_energies'] = local_energies\n",
    "    return calc_reaction_data\n",
    "\n",
    "\n",
    "def add_calc_reaction_data(reaction, calc_reaction_data):\n",
    "    calc_reaction_data['Weights'] = reaction['Weights']\n",
    "    calc_reaction_data['Densities'] = reaction['Densities']\n",
    "    return calc_reaction_data\n",
    "\n",
    "def backsplit(reaction, calc_reaction_data):\n",
    "    backsplit_ind = reaction['backsplit_ind'].type(torch.int)\n",
    "    splitted_data = dict()\n",
    "    stop = 0\n",
    "    \n",
    "    for i, component in enumerate(reaction['Components']):\n",
    "        splitted_data[component] = dict()\n",
    "        start = stop\n",
    "        stop = backsplit_ind[i]\n",
    "        for elem in ('Local_energies', 'Weights', 'Densities'):\n",
    "            splitted_data[component][elem] = calc_reaction_data[elem][start:stop]\n",
    "    return splitted_data\n",
    "\n",
    "\n",
    "def integration(reaction, splitted_calc_reaction_data):\n",
    "    molecule_energies = dict()\n",
    "    for i, component in enumerate(reaction['Components']):\n",
    "        molecule_energies[component] = torch.sum(splitted_calc_reaction_data[component]['Local_energies'] \\\n",
    "                                              * (splitted_calc_reaction_data[component]['Densities'][:,0] \\\n",
    "                                              + splitted_calc_reaction_data[component]['Densities'][:,1]) \\\n",
    "                                              * (splitted_calc_reaction_data[component]['Weights'])) \\\n",
    "                                              + reaction['HF_energies'][i]\n",
    "    return molecule_energies\n",
    "\n",
    "\n",
    "def get_energy_reaction(reaction, molecule_energies):\n",
    "    hartree2kcal = 627.5095\n",
    "    s = 0\n",
    "    for coef, ener in zip(reaction['Coefficients'], molecule_energies.values()):\n",
    "        s += coef*ener\n",
    "    reaction_energy_kcal = s * hartree2kcal\n",
    "    return reaction_energy_kcal\n",
    "\n",
    "\n",
    "def calculate_reaction_energy(reaction, constants):\n",
    "    local_energies = get_local_energies(reaction, constants)\n",
    "    calc_reaction_data = add_calc_reaction_data(reaction, local_energies)\n",
    "\n",
    "    splitted_calc_reaction_data = backsplit(reaction, calc_reaction_data)\n",
    "\n",
    "    molecule_energies = integration(reaction, splitted_calc_reaction_data)\n",
    "    \n",
    "    reaction_energy_kcal = get_energy_reaction(reaction, molecule_energies)\n",
    "\n",
    "    return reaction_energy_kcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_reactions_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'MGAE109',\n",
       " 'Components': array(['H_mgae109', 'H2_mgae109'], dtype=object),\n",
       " 'Coefficients': array([ 2., -1.]),\n",
       " 'Energy': 109.49,\n",
       " 'Grid': tensor([[3.1106e-01, 0.0000e+00, 3.6975e-09,  ..., 0.0000e+00, 1.4859e-09,\n",
       "          0.0000e+00],\n",
       "         [3.1106e-01, 0.0000e+00, 3.1224e-07,  ..., 0.0000e+00, 1.2547e-07,\n",
       "          0.0000e+00],\n",
       "         [3.1106e-01, 0.0000e+00, 4.1824e-06,  ..., 0.0000e+00, 1.6807e-06,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [3.3523e-04, 3.3523e-04, 5.3741e-07,  ..., 5.3741e-07, 2.0039e-04,\n",
       "          2.0039e-04],\n",
       "         [4.5250e-04, 4.5250e-04, 9.8983e-07,  ..., 9.8983e-07, 2.7344e-04,\n",
       "          2.7344e-04],\n",
       "         [3.3523e-04, 3.3523e-04, 5.3741e-07,  ..., 5.3741e-07, 2.0039e-04,\n",
       "          2.0039e-04]]),\n",
       " 'Weights': tensor([2.5717e-17, 9.9780e-15, 3.2611e-13,  ..., 2.6055e-02, 2.2680e-02,\n",
       "         2.6055e-02]),\n",
       " 'Densities': tensor([[0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         ...,\n",
       "         [0.0003, 0.0003],\n",
       "         [0.0005, 0.0005],\n",
       "         [0.0003, 0.0003]]),\n",
       " 'HF_energies': tensor([-0.1908, -0.4750]),\n",
       " 'backsplit_ind': tensor([ 33834., 101502.])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[73] # take the easiest reaction H2 = 2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_split(data, test_size, shuffle=False):\n",
    "    if shuffle:\n",
    "        keys = list(data.keys())\n",
    "        random.shuffle(keys)\n",
    "        for i in keys:\n",
    "            data[keys[i]] = data[i]\n",
    "\n",
    "    train, test = dict(), dict()\n",
    "    border = round(len(data.keys()) * (1 - test_size))\n",
    "    for i in range(len(data.keys())):\n",
    "        if i <= border:\n",
    "            train[i] = data[i]\n",
    "        else:\n",
    "            test[i] = data[i]\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.data[i]['Energy']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.keys())\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "data_train, data_test = train_split(copy.deepcopy(data), 0.2, True)\n",
    "\n",
    "\n",
    "train_set = Dataset(data=data_train)\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_set, \n",
    "#                                                batch_size=1)\n",
    "\n",
    "test_set = Dataset(data=data_test)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_set, \n",
    "#                                               batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = NN_8_256().to(device)\n",
    "model.load_state_dict(torch.load('predoptimized_2.param', map_location=device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, test_loader, n_epochs=20):\n",
    "    train_loss_mae = []\n",
    "    test_loss_mae = []\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        # train\n",
    "        model.train()\n",
    "        # progress_bar = tqdm(train_loader)\n",
    "\n",
    "        train_mae_losses_per_epoch = []\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch_grid, y_batch = torch.Tensor(X_batch['Grid']).to(device), torch.Tensor(np.array([y_batch])).to(device)\n",
    "            predictions = torch.expm1(model(X_batch_grid))\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions)\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            print(X_batch['Components'], loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_mae_losses_per_epoch.append(loss.item())\n",
    "        train_loss_mae.append(torch.mean(train_mae_losses_per_epoch))\n",
    "\n",
    "        # #test\n",
    "        # model.eval()\n",
    "        # test_mae_losses_per_epoch = []\n",
    "        # with torch.no_grad():\n",
    "        #     for X_batch, y_batch in test_loader:\n",
    "        #         X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "        #         preds = np.expm1(model(X_batch_grid))\n",
    "        #         reaction_energy = calculate_reaction_energy(X_batch, predictions)\n",
    "        #         loss = criterion(np.array(reaction_energy), np.array(y_batch))\n",
    "        #         test_mae_losses_per_epoch.append(loss.item())\n",
    "        # test_loss_mae.append(np.mean(test_mae_losses_per_epoch))\n",
    "        # print(f'train MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "        # print(f'test MAE Loss = {test_loss_mae[epoch]:.8f}')\n",
    "\n",
    "    return train_loss_mse, train_loss_mae, test_loss_mse, test_loss_mae, preds[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/python/jupyterhub2/lib/python3.10/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H2_htbh38' 'TS9_htbh38' 'F_nhtbh38'] nan\n",
      "['PH2+_ip13' 'PH2_ip13'] nan\n",
      "['H_mgae109' 'N_mgae109' 'NH2NH2_mgae109'] nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss_mse, train_loss_mae, test_loss_mse, test_loss_mae, preds \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     14\u001b[0m     X_batch_grid, y_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(X_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrid\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39marray([y_batch]))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexpm1(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch_grid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m     reaction_energy \u001b[38;5;241m=\u001b[39m calculate_reaction_energy(X_batch, predictions)\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(reaction_energy, y_batch)\n",
      "File \u001b[0;32m/opt/software/python/jupyterhub2/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/NN_models.py:26\u001b[0m, in \u001b[0;36mMLOptimizer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# x = f_svwn3(x)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/software/python/jupyterhub2/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/software/python/jupyterhub2/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/software/python/jupyterhub2/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/software/python/jupyterhub2/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_mse, train_loss_mae, test_loss_mse, test_loss_mae, preds = train(model, criterion, optimizer, \n",
    "                                                                            train_set,\n",
    "                                                                            test_set, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'MGAE109',\n",
       " 'Components': array(['H_mgae109', 'H2_mgae109'], dtype=object),\n",
       " 'Coefficients': array([ 2., -1.]),\n",
       " 'Energy': 109.49,\n",
       " 'Grid': tensor([[3.1106e-01, 0.0000e+00, 3.6975e-09,  ..., 0.0000e+00, 1.4859e-09,\n",
       "          0.0000e+00],\n",
       "         [3.1106e-01, 0.0000e+00, 3.1224e-07,  ..., 0.0000e+00, 1.2547e-07,\n",
       "          0.0000e+00],\n",
       "         [3.1106e-01, 0.0000e+00, 4.1824e-06,  ..., 0.0000e+00, 1.6807e-06,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [3.3523e-04, 3.3523e-04, 5.3741e-07,  ..., 5.3741e-07, 2.0039e-04,\n",
       "          2.0039e-04],\n",
       "         [4.5250e-04, 4.5250e-04, 9.8983e-07,  ..., 9.8983e-07, 2.7344e-04,\n",
       "          2.7344e-04],\n",
       "         [3.3523e-04, 3.3523e-04, 5.3741e-07,  ..., 5.3741e-07, 2.0039e-04,\n",
       "          2.0039e-04]]),\n",
       " 'Weights': tensor([2.5717e-17, 9.9780e-15, 3.2611e-13,  ..., 2.6055e-02, 2.2680e-02,\n",
       "         2.6055e-02]),\n",
       " 'Densities': tensor([[0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         ...,\n",
       "         [0.0003, 0.0003],\n",
       "         [0.0005, 0.0005],\n",
       "         [0.0003, 0.0003]]),\n",
       " 'HF_energies': tensor([-0.1908, -0.4750]),\n",
       " 'backsplit_ind': tensor([ 33834., 101502.])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction = data[73]\n",
    "reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = reaction\n",
    "y_batch = reaction['Energy']\n",
    "X_batch_grid, y_batch = X_batch['Grid'].to(device), torch.Tensor(np.array([y_batch])).to(device)\n",
    "\n",
    "predictions = torch.expm1(model(X_batch_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch_grid.requires_grad, y_batch.requires_grad = True, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([101502, 21]), torch.Size([101502, 7]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, X_batch_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 21])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_constants = torch.Tensor([0.0310907, 0.01554535, \n",
    "                3.72744,   7.06042,\n",
    "                12.9352,   18.0578,\n",
    "                -0.10498,  -0.32500,\n",
    "                0.0310907,  0.01554535,  -1/(6*torch.pi**2),\n",
    "                13.0720,    20.1231,      1.06835,\n",
    "                42.7198,   101.578,      11.4813,\n",
    "                -0.409286,  -0.743294,   -0.228344,\n",
    "                1])\n",
    "constants = torch.tile(true_constants, (101502,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.03109069913625717163)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.11082098633050918579e-02,  1.55354645103216171265e-02,\n",
       "         3.72747325897216796875e+00,  7.06047105789184570312e+00,\n",
       "         1.29351100921630859375e+01,  1.80580902099609375000e+01,\n",
       "        -1.04969792068004608154e-01, -3.25008869171142578125e-01,\n",
       "         3.10632865875959396362e-02,  1.55571084469556808472e-02,\n",
       "        -1.68711654841899871826e-02,  1.30721702575683593750e+01,\n",
       "         2.01230430603027343750e+01,  1.06832981109619140625e+00,\n",
       "         4.27197875976562500000e+01,  1.01578819274902343750e+02,\n",
       "         1.14812364578247070312e+01, -4.09288644790649414062e-01,\n",
       "        -7.43289113044738769531e-01, -2.28327989578247070312e-01,\n",
       "         9.99994635581970214844e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.09296204149723052979, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs((predictions[0]-constants[0])/constants[0]).max()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.10906991362571716309e-02,  1.55453495681285858154e-02,\n",
       "         3.72744011878967285156e+00,  7.06042003631591796875e+00,\n",
       "         1.29351997375488281250e+01,  1.80578002929687500000e+01,\n",
       "        -1.04979999363422393799e-01, -3.24999988079071044922e-01,\n",
       "         3.10906991362571716309e-02,  1.55453495681285858154e-02,\n",
       "        -1.68868638575077056885e-02,  1.30719995498657226562e+01,\n",
       "         2.01231002807617187500e+01,  1.06834995746612548828e+00,\n",
       "         4.27197990417480468750e+01,  1.01578002929687500000e+02,\n",
       "         1.14813003540039062500e+01, -4.09285992383956909180e-01,\n",
       "        -7.43294000625610351562e-01, -2.28343993425369262695e-01,\n",
       "         1.00000000000000000000e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'SVWN3' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/SVWN3.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import SVWN3\n",
    "reload(SVWN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "CPU times: user 388 ms, sys: 24 ms, total: 412 ms\n",
      "Wall time: 447 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "local_energies = get_local_energies(reaction, predictions) # 1k of 100k grid points for 2H = H2 system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(258)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_energies['Local_energies'].isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.66303867101669311523437500000000000000000000000000,\n",
       "        -0.66305744647979736328125000000000000000000000000000,\n",
       "        -0.66306197643280029296875000000000000000000000000000,\n",
       "         ...,\n",
       "        -0.08761207759380340576171875000000000000000000000000,\n",
       "        -0.09582035988569259643554687500000000000000000000000,\n",
       "        -0.08761709928512573242187500000000000000000000000000],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_energies['Local_energies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_sqrt = torch.load(\"tensor_sqrt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(tensor_sqrt).isnan().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = torch.load(\"tensor_faux_part1.pt\")\n",
    "arc = torch.load(\"tensor_faux_arc.pt\")\n",
    "vwn = torch.load(\"tensor_faux_vwn.pt\")\n",
    "Q = torch.load(\"tensor_faux_Q.pt\")\n",
    "arc_arg = torch.load(\"tensor_faux_arc_arg.pt\")\n",
    "b = torch.load(\"tensor_faux_b.pt\")\n",
    "c = torch.load(\"tensor_faux_c.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([170.87919616699218750000000000000000000000000000000000,\n",
       "        170.87927246093750000000000000000000000000000000000000,\n",
       "        170.87927246093750000000000000000000000000000000000000,\n",
       "        170.87672424316406250000000000000000000000000000000000,\n",
       "        170.87797546386718750000000000000000000000000000000000,\n",
       "        170.87751770019531250000000000000000000000000000000000,\n",
       "        170.87734985351562500000000000000000000000000000000000,\n",
       "        170.87797546386718750000000000000000000000000000000000,\n",
       "        170.87751770019531250000000000000000000000000000000000,\n",
       "        170.87689208984375000000000000000000000000000000000000],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*c[(arc*vwn).isnan()][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([170.87919616699218750000000000000000000000000000000000,\n",
       "        170.87927246093750000000000000000000000000000000000000,\n",
       "        170.87927246093750000000000000000000000000000000000000,\n",
       "        170.87672424316406250000000000000000000000000000000000,\n",
       "        170.87797546386718750000000000000000000000000000000000,\n",
       "        170.87751770019531250000000000000000000000000000000000,\n",
       "        170.87734985351562500000000000000000000000000000000000,\n",
       "        170.87797546386718750000000000000000000000000000000000,\n",
       "        170.87751770019531250000000000000000000000000000000000,\n",
       "        170.87689208984375000000000000000000000000000000000000],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b[(arc*vwn).isnan()]**2)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[(arc*vwn).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_arg[(arc*vwn).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(258)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwn.isnan().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(arc*vwn)[(arc*vwn).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc[(arc*vwn).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwn[(arc*vwn).isnan()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.97768485546112060546875000000000000000000000000000,\n",
       "        1.97768056392669677734375000000000000000000000000000,\n",
       "        1.97768008708953857421875000000000000000000000000000,\n",
       "         ...,\n",
       "        1.61100685596466064453125000000000000000000000000000,\n",
       "        1.63406682014465332031250000000000000000000000000000,\n",
       "        1.61100447177886962890625000000000000000000000000000],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_reaction_energy(reaction, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_reaction_energy(reaction, constants):\n",
    "    local_energies = get_local_energies(reaction, constants)\n",
    "    print(calc_reaction_data)\n",
    "    calc_reaction_data = add_calc_reaction_data(reaction, local_energies)\n",
    "    print(calc_reaction_data)\n",
    "    splitted_calc_reaction_data = backsplit(reaction, calc_reaction_data)\n",
    "    print(splitted_calc_reaction_data)\n",
    "    molecule_energies = integration(reaction, splitted_calc_reaction_data)\n",
    "    print(molecule_energies)\n",
    "    reaction_energy_kcal = get_energy_reaction(reaction, molecule_energies)\n",
    "    \n",
    "    \n",
    "    return reaction_energy_kcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_svwn3(reaction['Densities'].to('cpu')[0], predictions.to('cpu')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.548874855041504"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()/1024**3 # GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.11 [python-pytorch1_11]",
   "language": "python",
   "name": "conda-env-python-pytorch1_11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5e5bb8c7f59d999df07168cdddfd96f8fceb1d4deaee65f2787e1aa74655cd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
