{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.63 ms, sys: 2.87 ms, total: 6.5 ms\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import copy\n",
    "from torch import nn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from NN_models import NN_2_256, NN_8_256, NN_8_64\n",
    "from dataset import make_reactions_dict\n",
    "from reaction_energy_calculation import calculate_reaction_energy\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    # seed evetyting\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_random_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.46 s, sys: 4.54 s, total: 14 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# make a single dictionary from the whole dataset\n",
    "data = make_reactions_dict(path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Database': 'MGAE109',\n",
       " 'Components': array(['H_mgae109', 'H2_mgae109'], dtype='<U20'),\n",
       " 'Coefficients': tensor([ 2., -1.]),\n",
       " 'Energy': tensor(109.4900),\n",
       " 'Grid': tensor([[ -1.1678, -16.1181, -16.0818,  ..., -16.1181, -16.1033, -16.1181],\n",
       "         [ -1.1678, -16.1181, -14.7017,  ..., -16.1181, -15.3051, -16.1181],\n",
       "         [ -1.1678, -16.1181, -12.3610,  ..., -16.1181, -13.2385, -16.1181],\n",
       "         ...,\n",
       "         [ -8.0004,  -8.0004, -14.2658,  ..., -14.2658,  -8.5148,  -8.5148],\n",
       "         [ -7.7005,  -7.7005, -13.7295,  ..., -13.7295,  -8.2041,  -8.2041],\n",
       "         [ -8.0004,  -8.0004, -14.2658,  ..., -14.2658,  -8.5148,  -8.5148]]),\n",
       " 'Weights': tensor([2.5717e-17, 9.9780e-15, 3.2611e-13,  ..., 2.6055e-02, 2.2680e-02,\n",
       "         2.6055e-02]),\n",
       " 'Densities': tensor([[0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         [0.3111, 0.0000],\n",
       "         ...,\n",
       "         [0.0003, 0.0003],\n",
       "         [0.0005, 0.0005],\n",
       "         [0.0003, 0.0003]]),\n",
       " 'HF_energies': tensor([-0.1908, -0.4750]),\n",
       " 'backsplit_ind': tensor([ 33834., 101502.])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[73] # take the easiest reaction H2 = 2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_keys(data):\n",
    "    # turns reaction_data dict keys names into numbers\n",
    "    \n",
    "    l = len(data)\n",
    "    keys = data.keys()\n",
    "    data_new = {}\n",
    "    for i, key in zip(range(l), keys):\n",
    "        data_new[i] = data[key]\n",
    "    return data_new\n",
    "\n",
    "\n",
    "def train_split(data, test_size, shuffle=False):\n",
    "    # returns train and test reaction dictionaries\n",
    "    if shuffle:\n",
    "        keys = list(data.keys())\n",
    "        random.shuffle(keys)\n",
    "        for i in keys:\n",
    "            data[keys[i]] = data[i]\n",
    "\n",
    "    train, test = dict(), dict()\n",
    "    border = round(len(data.keys()) * (1 - test_size))\n",
    "    for i in range(len(data.keys())):\n",
    "        if i <= border:\n",
    "            train[i] = data[i]\n",
    "        else:\n",
    "            test[i] = data[i]\n",
    "    return rename_keys(train), rename_keys(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        i = 1\n",
    "        self.data[i].pop('Database', None)\n",
    "\n",
    "        return self.data[i], self.data[i]['Energy']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.keys())\n",
    "\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "data_train, data_test = train_split(copy.deepcopy(data), test_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_set = Dataset(data=data_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, \n",
    "                                               batch_size=None,\n",
    "                                               num_workers=1,\n",
    "                                               pin_memory=True,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_set = Dataset(data=data_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, \n",
    "                                              batch_size=None,\n",
    "                                              num_workers=1,\n",
    "                                              pin_memory=True,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88862460, 7])\n"
     ]
    }
   ],
   "source": [
    "#standard scaler\n",
    "lst = []\n",
    "for i in range(len(data)):\n",
    "    lst.append(data[i]['Grid'])\n",
    "    \n",
    "all_grid_data = torch.cat(lst)\n",
    "print(all_grid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.66 s, sys: 1.4 s, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "stdscaler = StandardScaler()\n",
    "stdscaler.fit(np.array(all_grid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_models import NN_2_256, NN_8_256, NN_8_64\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "\n",
    "model = NN_8_256(DFT='SVWN').to(device)\n",
    "# model.load_state_dict(torch.load('predopt/predopt_8_256_log.param', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GPUtil import showUtilization as gpu_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_file_path = 'epoch_training.log'\n",
    "if os.path.isfile(log_file_path):\n",
    "    os.remove(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, test_loader, n_epochs=20, accum_iter=4):\n",
    "    train_loss_mae = []\n",
    "    train_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "    accum_iter = accum_iter \n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        # train\n",
    "        \n",
    "        model.train()\n",
    "        progress_bar_train = tqdm(train_loader)\n",
    "        train_mae_losses_per_epoch = []\n",
    "        train_mse_losses_per_epoch = []\n",
    "        for batch_idx, X_batch, y_batch in enumetate(progress_bar_train):\n",
    "            \n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch_grid)\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device)\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            \n",
    "            # loss_accumulation\n",
    "            loss = loss / accum_iter\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(data_loader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            MSE = loss.item()\n",
    "            MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "            train_mse_losses_per_epoch.append(MSE)\n",
    "            train_mae_losses_per_epoch.append(MAE)\n",
    "            progress_bar_train.set_postfix(MSE = MSE, MAE = MAE)\n",
    "            preds = predictions[0].cpu().detach().numpy()\n",
    "            \n",
    "            with open('epoch_training.log', 'a') as f:\n",
    "                f.write(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\\n\")\n",
    "                # f.write(f\"{preds}\\n\")\n",
    "            \n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # gpu_usage()\n",
    "        \n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))        \n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'train MSE Loss = {train_loss_mse[epoch]:.8f} MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "\n",
    "\n",
    "        \n",
    "        #test\n",
    "        # progress_bar_test = tqdm(test_loader)\n",
    "        model.eval()\n",
    "        test_mae_losses_per_epoch = []\n",
    "        test_mse_losses_per_epoch = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "                predictions = model(X_batch_grid)\n",
    "                reaction_energy = calculate_reaction_energy(X_batch, predictions, device)\n",
    "                loss = criterion(reaction_energy, y_batch)\n",
    "                MSE = loss.item()\n",
    "                MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "                progress_bar_train.set_postfix(MAE = MAE)\n",
    "                test_mse_losses_per_epoch.append(MSE)\n",
    "                test_mae_losses_per_epoch.append(MAE)\n",
    "                \n",
    "                with open('epoch_training.log', 'a') as f:\n",
    "                    f.write(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\\n\")\n",
    "                \n",
    "                del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        test_loss_mse.append(np.mean(test_mse_losses_per_epoch))\n",
    "        test_loss_mae.append(np.mean(test_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'test MSE Loss = {test_loss_mse[epoch]:.8f} MAE Loss = {test_loss_mae[epoch]:.8f}')\n",
    "\n",
    "    return train_loss_mae, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import SVWN3\n",
    "reload(SVWN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_mae, preds = train(model, criterion, optimizer, \n",
    "                              train_dataloader,\n",
    "                              test_dataloader, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lda(train_loader, test_loader, c_arr, criterion, n_epochs=1):\n",
    "    train_loss_mae = []\n",
    "    train_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        # train\n",
    "        \n",
    "        model.train()\n",
    "        progress_bar_train = tqdm(train_loader)\n",
    "        train_mae_losses_per_epoch = []\n",
    "        train_mse_losses_per_epoch = []\n",
    "        for X_batch, y_batch in progress_bar_train:\n",
    "            # print(f\"{X_batch['Components']}\")\n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            # print(torch.tile(c_arr, [X_batch_grid.shape[0],1]))\n",
    "            predictions = torch.tile(c_arr, [X_batch_grid.shape[0],1]).to(device)\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device)\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            MSE = loss.item()\n",
    "            MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "            train_mse_losses_per_epoch.append(MSE)\n",
    "            train_mae_losses_per_epoch.append(MAE)\n",
    "            progress_bar_train.set_postfix(MSE = MSE, MAE = MAE)\n",
    "            print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\")\n",
    "\n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))        \n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'train MSE Loss = {train_loss_mse[epoch]:.8f} MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "\n",
    "\n",
    "        \n",
    "        #test\n",
    "        # progress_bar_test = tqdm(test_loader)\n",
    "        model.eval()\n",
    "        test_mae_losses_per_epoch = []\n",
    "        test_mse_losses_per_epoch = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                # print(f\"{X_batch['Components']}\")\n",
    "                X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "                predictions = torch.tile(c_arr, (X_batch_grid.shape[0],1)).to(device)\n",
    "                reaction_energy = calculate_reaction_energy(X_batch, predictions, device)\n",
    "                loss = criterion(reaction_energy, y_batch)\n",
    "                MSE = loss.item()\n",
    "                MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "                # progress_bar_train.set_postfix(MAE = MAE)\n",
    "                test_mse_losses_per_epoch.append(MSE)\n",
    "                test_mae_losses_per_epoch.append(MAE)\n",
    "                print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\")\n",
    "                \n",
    "                del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        test_loss_mse.append(np.mean(test_mse_losses_per_epoch))\n",
    "        test_loss_mae.append(np.mean(test_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'test MSE Loss = {test_loss_mse[epoch]:.8f} MAE Loss = {test_loss_mae[epoch]:.8f}')\n",
    "\n",
    "    return train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import reaction_energy_calculation\n",
    "reload(reaction_energy_calculation)\n",
    "\n",
    "\n",
    "# import SVWN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_constants = torch.Tensor([0.0310907, 0.01554535, \n",
    "                3.72744,   7.06042,\n",
    "                12.9352,   18.0578,\n",
    "                -0.10498,  -0.32500,\n",
    "                0.0310907,  0.01554535,  -1/(6*torch.pi**2),\n",
    "                13.0720,    20.1231,      1.06835,\n",
    "                42.7198,   101.578,      11.4813,\n",
    "                -0.409286,  -0.743294,   -0.228344,\n",
    "                1])\n",
    "\n",
    "# true_constants\n",
    "\n",
    "test_lda(train_dataloader, test_dataloader, true_constants, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.11 [python-pytorch1_11]",
   "language": "python",
   "name": "conda-env-python-pytorch1_11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5e5bb8c7f59d999df07168cdddfd96f8fceb1d4deaee65f2787e1aa74655cd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
