{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 342 µs, sys: 61 µs, total: 403 µs\n",
      "Wall time: 414 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "import random\n",
    "from torch import nn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm.notebook import tqdm\n",
    "from NN_models import NN_2_256, NN_4_256, NN_8_256, NN_8_64, NN_4_128, NN_8_128\n",
    "from reaction_energy_calculation import calculate_reaction_energy\n",
    "from prepare_data import prepare, save_chk, load_chk\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    # seed everything\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# data, data_train, data_test = prepare(path='data', test_size=0.2)\n",
    "\n",
    "# %%time\n",
    "# save_chk(data, data_train, data_test, path='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 3.77 s, total: 8.47 s\n",
      "Wall time: 8.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data, data_train, data_test = load_chk(path='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        self.data[i].pop('Database', None)\n",
    "\n",
    "        return self.data[i], self.data[i]['Energy']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.keys())\n",
    "\n",
    "\n",
    "train_set = Dataset(data=data_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, \n",
    "                                               batch_size=None,\n",
    "                                               num_workers=1,\n",
    "                                               pin_memory=True,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_set = Dataset(data=data_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, \n",
    "                                              batch_size=None,\n",
    "                                              num_workers=1,\n",
    "                                              pin_memory=True,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(device)\n",
    "criterion = nn.MSELoss()\n",
    "model = NN_4_256(nconstants=24, DFT='PBE').to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model_chk/predopt/PBE_4_256.param', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'NN_models' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/NN_models.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import predopt\n",
    "reload(predopt)\n",
    "import NN_models\n",
    "reload(NN_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 µs, sys: 0 ns, total: 215 µs\n",
      "Wall time: 225 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from predopt import DatasetPredopt\n",
    "train_predopt_set = DatasetPredopt(data=data, dft='PBE')\n",
    "train_predopt_dataloader = torch.utils.data.DataLoader(train_predopt_set,\n",
    "                                                       batch_size=None,\n",
    "                                                       num_workers=1,\n",
    "                                                       pin_memory=True,\n",
    "                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5, betas=(0.9, 0.999), weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 0.00020600\n",
      "train MAE Loss = 0.00589636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.00020599788444400992], [0.0058963555])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predopt import predopt\n",
    "\n",
    "predopt(model, criterion, optimizer, train_predopt_dataloader, device, n_epochs=1, accum_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad owner or permissions on /home/duzaripov/.ssh/config\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_chk/predopt/PBE_4_256.param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp model_chk/predopt/PBE_4_256.param model_chk/predopt/PBE_4_256.param_backup3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "log_file_path = 'log/epoch_training.log'\n",
    "\n",
    "if os.path.isfile(log_file_path):\n",
    "    os.remove(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, test_loader, n_epochs=20, accum_iter=4, verbose=False):\n",
    "    train_loss_mae = []\n",
    "    train_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        # train\n",
    "        model.train()\n",
    "        progress_bar_train = tqdm(train_loader)\n",
    "        train_mae_losses_per_epoch = []\n",
    "        train_mse_losses_per_epoch = []\n",
    "        optimizer.zero_grad()\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(progress_bar_train):\n",
    "            \n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            predictions = model(X_batch_grid)\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung='GGA', dft='PBE')\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f}\")\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            MSE = loss.item()\n",
    "            MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "            print(MAE)\n",
    "            train_mse_losses_per_epoch.append(MSE)\n",
    "            train_mae_losses_per_epoch.append(MAE)\n",
    "            progress_bar_train.set_postfix(MSE = MSE, MAE = MAE)\n",
    "            \n",
    "            with open(log_file_path, 'a') as f:\n",
    "                f.write(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\\n\")\n",
    "            \n",
    "            # loss_accumulation\n",
    "            loss = loss / accum_iter\n",
    "            loss.backward()\n",
    "            if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(train_loader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # gpu_usage()\n",
    "        \n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))        \n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'train MSE Loss = {train_loss_mse[epoch]:.8f} MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "\n",
    "\n",
    "        \n",
    "        #test\n",
    "        model.eval()\n",
    "        progress_bar_test = tqdm(test_loader)\n",
    "        test_mae_losses_per_epoch = []\n",
    "        test_mse_losses_per_epoch = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in progress_bar_test:\n",
    "                X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "                # print(f\"{X_batch['Components']}\")\n",
    "                predictions = model(X_batch_grid)\n",
    "                reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung='GGA', dft='PBE')\n",
    "                loss = criterion(reaction_energy, y_batch)\n",
    "                MSE = loss.item()\n",
    "                MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "                test_mse_losses_per_epoch.append(MSE)\n",
    "                test_mae_losses_per_epoch.append(MAE)\n",
    "                progress_bar_test.set_postfix(MSE = MSE, MAE = MAE)\n",
    "\n",
    "                \n",
    "                with open(log_file_path, 'a') as f:\n",
    "                    f.write(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\\n\")\n",
    "                del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        test_loss_mse.append(np.mean(test_mse_losses_per_epoch))\n",
    "        test_loss_mae.append(np.mean(test_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'test MSE Loss = {test_loss_mse[epoch]:.8f} MAE Loss = {test_loss_mae[epoch]:.8f}')\n",
    "\n",
    "    return train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PBE' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/PBE.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import PBE\n",
    "import reaction_energy_calculation\n",
    "import utils\n",
    "import NN_models\n",
    "reload(NN_models)\n",
    "reload(utils)\n",
    "reload(reaction_energy_calculation)\n",
    "reload(PBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN_4_256(nconstants=24, DFT='PBE').to(device)\n",
    "model.zero_grad()\n",
    "# model.load_state_dict(torch.load('model_chk/predopt/PBE_4_256.param', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.73004150390625\n",
      "70.08631134033203\n",
      "12.52762222290039\n",
      "41.67515563964844\n",
      "317.76318359375\n",
      "c_arr is NaN\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NaN detected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss_mae \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, n_epochs, accum_iter, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m X_batch_grid, y_batch \u001b[38;5;241m=\u001b[39m X_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(X_batch_grid)\n\u001b[0;32m---> 19\u001b[0m reaction_energy \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_reaction_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrung\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGGA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPBE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponents\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pred \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreaction_energy\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m true \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_batch\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/reaction_energy_calculation.py:72\u001b[0m, in \u001b[0;36mcalculate_reaction_energy\u001b[0;34m(reaction, constants, device, rung, dft)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_reaction_energy\u001b[39m(reaction, constants, device, rung, dft):\n\u001b[0;32m---> 72\u001b[0m     local_energies \u001b[38;5;241m=\u001b[39m \u001b[43mget_local_energies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreaction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrung\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_energies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocal_energies\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28mprint\u001b[39m(local_energies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocal_energies\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/reaction_energy_calculation.py:22\u001b[0m, in \u001b[0;36mget_local_energies\u001b[0;34m(reaction, constants, device, rung, dft)\u001b[0m\n\u001b[1;32m     20\u001b[0m gradients \u001b[38;5;241m=\u001b[39m (reaction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradients\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dft \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 22\u001b[0m     local_energies \u001b[38;5;241m=\u001b[39m \u001b[43mF_PBE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdensities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dft \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBE_new\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     24\u001b[0m     local_energies \u001b[38;5;241m=\u001b[39m F_PBE_new(densities, gradients, constants)\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/PBE.py:196\u001b[0m, in \u001b[0;36mF_PBE\u001b[0;34m(rho, sigmas, c_arr)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mF_PBE\u001b[39m(rho, sigmas, c_arr):\n\u001b[0;32m--> 196\u001b[0m     \u001b[43mcatch_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigmas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_arr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     rs, z \u001b[38;5;241m=\u001b[39m rs_z_calc(rho)\n\u001b[1;32m    198\u001b[0m     xs0, xs1, xt \u001b[38;5;241m=\u001b[39m xs_xt_calc(rho, sigmas)\n",
      "File \u001b[0;32m~/ML-parameterization-of-DFT-functionals/utils.py:19\u001b[0m, in \u001b[0;36mcatch_nan\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_printoptions(precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     18\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(v, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN detected\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inf_detected \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mValueError\u001b[0m: NaN detected"
     ]
    }
   ],
   "source": [
    "train_loss_mae = train(model, criterion, optimizer,\n",
    "                       train_dataloader, test_dataloader,\n",
    "                       n_epochs=1, accum_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dft(train_loader, test_loader, c_arr, criterion, rung, dft, verbose=False, n_epochs=1, model_eval=False):\n",
    "    train_loss_mae = []\n",
    "    train_loss_mse = []\n",
    "    test_loss_mae = []\n",
    "    test_loss_mse = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        # train\n",
    "\n",
    "        progress_bar_train = tqdm(train_loader)\n",
    "        train_mae_losses_per_epoch = []\n",
    "        train_mse_losses_per_epoch = []\n",
    "        for X_batch, y_batch in progress_bar_train:\n",
    "            # print(f\"{X_batch['Components']}\")\n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            # print(torch.tile(c_arr, [X_batch_grid.shape[0],1]))\n",
    "            if model_eval:\n",
    "                predictions = model(X_batch_grid)\n",
    "            else:\n",
    "                predictions = torch.tile(c_arr, [X_batch_grid.shape[0],1]).to(device)\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung, dft)\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            MSE = loss.item()\n",
    "            MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "            train_mse_losses_per_epoch.append(MSE)\n",
    "            train_mae_losses_per_epoch.append(MAE)\n",
    "            progress_bar_train.set_postfix(MSE = MSE, MAE = MAE)\n",
    "            if verbose:\n",
    "                print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\")\n",
    "\n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        train_loss_mse.append(np.mean(train_mse_losses_per_epoch))        \n",
    "        train_loss_mae.append(np.mean(train_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'train MSE Loss = {train_loss_mse[epoch]:.8f} MAE Loss = {train_loss_mae[epoch]:.8f}')\n",
    "\n",
    "\n",
    "        \n",
    "        #test\n",
    "        progress_bar_test = tqdm(test_loader)\n",
    "        test_mae_losses_per_epoch = []\n",
    "        test_mse_losses_per_epoch = []\n",
    "        for X_batch, y_batch in progress_bar_test:\n",
    "            # print(f\"{X_batch['Components']}\")\n",
    "            X_batch_grid, y_batch = X_batch['Grid'].to(device), y_batch.to(device)\n",
    "            if model_eval:\n",
    "                predictions = model(X_batch_grid)\n",
    "            else:\n",
    "                predictions = torch.tile(c_arr, [X_batch_grid.shape[0],1]).to(device)\n",
    "            reaction_energy = calculate_reaction_energy(X_batch, predictions, device, rung, dft)\n",
    "            loss = criterion(reaction_energy, y_batch)\n",
    "            MSE = loss.item()\n",
    "            MAE = torch.abs(reaction_energy - y_batch).item()\n",
    "            # progress_bar_train.set_postfix(MAE = MAE)\n",
    "            test_mse_losses_per_epoch.append(MSE)\n",
    "            test_mae_losses_per_epoch.append(MAE)\n",
    "            if verbose:\n",
    "                print(f\"{X_batch['Components']} pred {reaction_energy.item():4f} true {y_batch.item():4f} MSE {MSE:4f} MAE {MAE:4f}\")\n",
    "            \n",
    "            del X_batch, X_batch_grid, y_batch, predictions, reaction_energy, loss, MAE, MSE\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "                \n",
    "        test_loss_mse.append(np.mean(test_mse_losses_per_epoch))\n",
    "        test_loss_mae.append(np.mean(test_mae_losses_per_epoch))\n",
    "\n",
    "        print(f'test MSE Loss = {test_loss_mse[epoch]:.8f} MAE Loss = {test_loss_mae[epoch]:.8f}')\n",
    "\n",
    "    return train_loss_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import NN_models\n",
    "reload(NN_models)\n",
    "from NN_models import NN_2_256, NN_8_256, NN_8_64\n",
    "# import SVWN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PBE' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/PBE.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import PBE\n",
    "import reaction_energy_calculation\n",
    "import utils\n",
    "import NN_models\n",
    "reload(NN_models)\n",
    "reload(utils)\n",
    "reload(reaction_energy_calculation)\n",
    "reload(PBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61537860ed4546bebf154bd5c123b08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE Loss = 11108.82772111 MAE Loss = 76.07116647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c69f4d08af64ac6a91cf821f206648d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE Loss = 7573.58364240 MAE Loss = 65.99973547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[76.07116646517154]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_constants_SVWN = torch.Tensor([0.0310907, 0.01554535, \n",
    "                3.72744,   7.06042,\n",
    "                12.9352,   18.0578,\n",
    "                -0.10498,  -0.32500,\n",
    "                0.0310907,  0.01554535,  -1/(6*torch.pi**2),\n",
    "                13.0720,    20.1231,      1.06835,\n",
    "                42.7198,   101.578,      11.4813,\n",
    "                -0.409286,  -0.743294,   -0.228344,\n",
    "                1])\n",
    "\n",
    "true_constants_PBE = torch.Tensor([[0.06672455,\n",
    "       (1 - torch.log(torch.Tensor([2])))/(torch.pi**2),\n",
    "       1.709921,\n",
    "       7.5957, 14.1189, 10.357,\n",
    "       3.5876, 6.1977, 3.6231,\n",
    "       1.6382, 3.3662,  0.88026,\n",
    "       0.49294, 0.62517, 0.49671,\n",
    "       # 1,  1,  1,\n",
    "       0.031091, 0.015545, 0.016887,\n",
    "       0.21370,  0.20548,  0.11125,\n",
    "       -3/8*(3/torch.pi)**(1/3)*4**(2/3),\n",
    "       0.8040,\n",
    "       0.2195149727645171]])\n",
    "\n",
    "par_rpw92_constants = torch.Tensor([[0.06672455,\n",
    "       (1 - torch.log(torch.Tensor([2])))/(torch.pi**2),\n",
    "       1.709920934161365617563962776245,\n",
    "       7.5957, 14.1189, 10.357,\n",
    "       3.5876, 6.1977, 3.6231,\n",
    "       1.6382, 4.86059,  0.88026,\n",
    "       0.49294, 0.750188, 0.49671,\n",
    "       # 1,  1,  1,\n",
    "       0.0310907, 0.01554535, 0.0168869,\n",
    "       0.21370,  0.266529,  0.11125,\n",
    "       -3/8*(3/torch.pi)**(1/3)*4**(2/3),\n",
    "       0.8040,\n",
    "       0.2195149727645171]])\n",
    "\n",
    "\n",
    "# true_constants\n",
    "\n",
    "test_dft(train_dataloader, test_dataloader, true_constants_PBE, criterion, rung='GGA', dft='PBE', verbose=False, model_eval=True)\n",
    "# test_dft(train_dataloader, test_dataloader, true_constants_SVWN, criterion, rung='LDA', dft='SVWN3', verbose=False)\n",
    "\n",
    "# broken_PBE 45.47375717 35.76542641\n",
    "# Mean Absolute Error, kcal/mol\n",
    "# DFT              train        test\n",
    "# SVWN3            32.63222432 26.81526929\n",
    "# PBE_sigma_broken 7.84055060  7.63013082\n",
    "# PBE_fixed        7.85833597  7.64929252\n",
    "# PBE_pred_4_256      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import PBE\n",
    "import reaction_energy_calculation\n",
    "import utils\n",
    "import NN_models\n",
    "reload(NN_models)\n",
    "reload(utils)\n",
    "reload(reaction_energy_calculation)\n",
    "reload(PBE)\n",
    "from reaction_energy_calculation import calculate_reaction_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PBE' from '/home/duzaripov/ML-parameterization-of-DFT-functionals/PBE.py'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import PBE\n",
    "reload(PBE)\n",
    "# from PBE_new import F_PBE_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(104.6450347900390625000000000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_reaction_energy(data[73], torch.tile(true_constants_PBE, [data[73]['Grid'].shape[0],1]).to(device='cpu'), device='cpu', rung='GGA', dft='PBE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.11 [python-pytorch1_11]",
   "language": "python",
   "name": "conda-env-python-pytorch1_11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5e5bb8c7f59d999df07168cdddfd96f8fceb1d4deaee65f2787e1aa74655cd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
